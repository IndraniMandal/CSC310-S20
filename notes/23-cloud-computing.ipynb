{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"23-cloud-computing.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"irV5oZ2UftET"},"source":["# preamble to be able to run notebooks in Jupyter and Colab\n","try:\n","    from google.colab import drive\n","    import sys\n","    \n","    drive.mount('/content/drive')\n","    notes_home = \"/content/drive/Shared drives/CSC310/ds/notes/\"\n","    user_home = \"/content/drive/My Drive/\"\n","    \n","    sys.path.insert(1,notes_home) # let the notebook access the notes folder\n","    \n","except ModuleNotFoundError:\n","    notes_home = \"\" # running native Jupyter environment -- notes home is the same as the notebook\n","    user_home = \"\"  # under Jupyter we assume the user directory is the same as the notebook"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aRuzl6CMftEV"},"source":["# Cloud Computing\n","\n","**Definition**: Cloud computing is the on-demand availability of computer system resources, especially data storage and computing power, without direct active management by the user. Cloud computing relies on sharing of resources to achieve coherence and [economies of scale](https://en.wikipedia.org/wiki/Economies_of_scale).\n","\n","[-Wikipedia](https://en.wikipedia.org/wiki/Cloud_computing)"]},{"cell_type":"markdown","metadata":{"id":"Rqi_59I7ftEW"},"source":["## Architecture\n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Cloud_computing.svg/1280px-Cloud_computing.svg.png\" height=\"350\" width=\"500\">\n","\n","**Cloud computing metaphor**: the group of networked elements providing services need not be individually addressed or managed by users; instead, the entire provider-managed suite of hardware and software can be thought of as an **amorphous cloud**.\n","\n","Googles Colab Notebooks is an example of application based cloud computing (for that matter their whole suite of application falls into that category)."]},{"cell_type":"markdown","metadata":{"id":"PTjrOUEAftEW"},"source":["## Service Models"]},{"cell_type":"markdown","metadata":{"id":"l62mZD9tftEX"},"source":["* [Software as a service (SaaS)](https://en.wikipedia.org/wiki/Cloud_computing#Software_as_a_service_(SaaS))\n","    \n","    **Definition**: The capability provided to the consumer is to use the provider's applications running on a cloud infrastructure. \n","    <!-- The applications are accessible from various client devices through either a thin client interface, such as a web browser (e.g., web-based email), or a program interface. The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage, or even individual application capabilities, with the possible exception of limited user-specific application configuration settings. -->\n","    \n","    **Examples**: Google Docs and Colab Notebooks\n"," "]},{"cell_type":"markdown","metadata":{"id":"AWx42g1xftEX"},"source":["   \n","* [Platform as a service (PaaS)](https://en.wikipedia.org/wiki/Cloud_computing#Platform_as_a_service_(PaaS))\n","\n","    **Definition**: The capability provided to the consumer is to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages, libraries, services, and tools supported by the provider. \n","    <!-- The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, or storage, but has control over the deployed applications and possibly configuration settings for the application-hosting environment.-->\n","    \n","    **Examples**: AWS Sagemaker and S3\n"," "]},{"cell_type":"markdown","metadata":{"id":"qs7IHFCYftEX"},"source":["   \n","* [Infrastructure as a service (IaaS)](https://en.wikipedia.org/wiki/Cloud_computing#Infrastructure_as_a_service_(IaaS))\n","\n","    **Definition**: The consumer is able to deploy and run arbitrary software, which can include operating systems and applications and has control over operating systems, storage, and deployed applications.\n","    \n","    **Examples**: AWS and Azure"]},{"cell_type":"markdown","metadata":{"id":"WC092AZOftEY"},"source":["## Data Science in the Cloud"]},{"cell_type":"markdown","metadata":{"id":"E1lyTEdpftEY"},"source":["<img src=\"https://dmhnzl5mp9mj6.cloudfront.net/bigdata_awsblog/images/White_paper_image1.PNG\" width=\"600\" height=\"200\">"]},{"cell_type":"markdown","metadata":{"id":"lZI5RzJjftEZ"},"source":["A cloud-based architecture of a data science processing pipeline taking advantage of AWS' IaaS.  All the components can be provisioned and configured in AWS console or through their DevOps API.  ([Source](https://aws.amazon.com/blogs/big-data/big-data-analytics-options-on-aws-updated-white-paper/))\n","\n","We will take a look at two components in the above diagram:"]},{"cell_type":"markdown","metadata":{"id":"PqZxie_-ftEZ"},"source":["* Cloud-based Storage: [S3](https://aws.amazon.com/s3/) (component #3)\n","    \n","    Amazon Simple Storage Service (Amazon S3) is an object storage service that offers scalability, data availability, security, and performance.\n","  "]},{"cell_type":"markdown","metadata":{"id":"fUaRS0-eftEa"},"source":["  \n","* Cloud-based Machine Learning: [Sagemaker](https://aws.amazon.com/sagemaker/) (component #5)\n","    \n","    Amazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models quickly. "]},{"cell_type":"markdown","metadata":{"id":"f0m-WZwwftEa"},"source":["## Experiments\n","\n","\n","If you have an AWS account here are two nice tutorials\n","\n","* [s3 tutorial](https://aws.amazon.com/getting-started/hands-on/backup-files-to-amazon-s3/)\n","\n","* [Jupyter/Sagemaker](https://aws.amazon.com/getting-started/hands-on/build-train-deploy-machine-learning-model-sagemaker/)\n","\n","We will be doing work in AWS Classrooms."]},{"cell_type":"markdown","metadata":{"id":"FccbC0m8ftEa"},"source":["### Exercise 1\n","\n","1. Goto the S3 console.\n","1. Create a bucket.\n","1. Upload the 'tennis-numeric.csv' file into your bucket.\n","1. Using the SQL interface figure out what the average temperature is for the week. \n","    * Make sure you ticked off the 'File has header row' box.  \n","    * Query: select avg(cast(temperature as integer)) from s3object\n","    * Note that you have to explicitly cast the temperature column as integer!\n"," \n","1. Using the SQL interface figure out how often we play or not play tennis in that week.\n","    * Query: select count(play) from s3object where cast(play as string) like '%yes%'\n","    * Note that you have to use 'like' with wildcard characters '%' in order to match 'yes' in case there are \n","        hidden characters.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"P7fll1LiftEb"},"source":["### Exercise 2\n","\n","1. Goto the Sagemaker notebooks console.\n","1. Create a notebook instance and open it in the Jupyter console.\n","1. Create a notebook to do the following:\n","    1. Access your play tennis data set stored in S3.\n","    1. Build a decision tree\n","    1. Print the tree and its accuracy"]},{"cell_type":"markdown","metadata":{"id":"r27CIjR1ftEb"},"source":["### The following code snippets will be useful for the above exercises\n","\n","Cut and paste them into your Sagemaker notebook"]},{"cell_type":"markdown","metadata":{"id":"_ByZ8OBBftEc"},"source":["```Python\n","# Accessing buckets for Machine Learning in Sagemaker\n","\n","import s3fs\n","import pandas as pd\n","\n","df = pd.read_csv('s3://<bucket-name>/<filename>.csv')\n","df.head()\n","```"]},{"cell_type":"markdown","metadata":{"id":"HTbiX-oTftEc"},"source":["```Python\n","# print decision tree\n","\n","import operator\n","\n","def tree_print(clf, X):\n","    tlevel = _tree_rprint('', clf, X.columns, clf.classes_)\n","    print('<',end='')\n","    for i in range(3*tlevel - 2):\n","        print('-',end='')\n","    print('>')\n","    print('Tree Depth: ',tlevel)\n","\n","def _tree_rprint(kword, clf, features, labels, node_index=0, tlevel_index=0):\n","    for i in range(tlevel_index):\n","        print('  |',end='')\n","    if clf.tree_.children_left[node_index] == -1:  # indicates leaf\n","        print(kword, end=' ' if kword else '')\n","        # get the majority label\n","        count_list = clf.tree_.value[node_index, 0]\n","\n","        if len(count_list) == 1:\n","            # regression problem\n","            print(count_list[0])\n","        else:\n","            # get the majority label\n","            max_index, max_value = max(enumerate(count_list), key=operator.itemgetter(1))\n","            max_label = labels[max_index]\n","            print(max_label)\n","        return tlevel_index\n","    \n","    else:\n","        # compute and print node label\n","        feature = features[clf.tree_.feature[node_index]]\n","        threshold = clf.tree_.threshold[node_index]\n","        print(kword, end=' ' if kword else '')\n","        print('if {} =< {}: '.format(feature, threshold))\n","        # recurse down the children\n","        left_index = clf.tree_.children_left[node_index]\n","        right_index = clf.tree_.children_right[node_index]\n","        ltlevel_index = _tree_rprint('then', clf, features, labels, left_index, tlevel_index+1)\n","        rtlevel_index = _tree_rprint('else', clf, features, labels, right_index, tlevel_index+1)\n","        # return the maximum depth of either one of the children\n","        return max(ltlevel_index,rtlevel_index)\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"a8Itn4JoftEd"},"source":["```Python\n","from sklearn import tree\n","from sklearn.metrics import accuracy_score\n","\n","# set up data\n","X  = df.drop(['play'],axis=1)\n","y = df['play']\n","\n","# set up the tree model object - limit the complexity to put us somewhere in the middle of the graph.\n","model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=None)\n","\n","# fit the model on the training set of data\n","model.fit(X, y)\n","\n","# evaluate model\n","tree_print(model,X)\n","y_model = model.predict(X)\n","acc = accuracy_score(y, y_model)\n","print(\"Accuracy: {:3.2f}\".format(acc))\n","```"]},{"cell_type":"markdown","metadata":{"id":"QBm2Yrd1ftEd"},"source":["### Exercise 3\n","\n","Query your bucket from your Sagemaker notebook and answer the same questions from exercise 2.\n","\n","The following snippets will be helpful."]},{"cell_type":"markdown","metadata":{"id":"hrAq5dkIftEd"},"source":["```Python\n","import pandas as pd\n","import boto3\n","from io import StringIO\n","\n","def query_bucket(sql, bucket, key):\n","    '''\n","    Query an S3 bucket using 'Select From SQL' syntax.\n","    If data was found then return a dataframe otherwise\n","    return 'None'.\n","    '''\n","    s3 = boto3.client('s3')\n","\n","    resp = s3.select_object_content(\n","        Bucket=bucket,\n","        Key=key,\n","        ExpressionType='SQL',\n","        Expression=sql,\n","        InputSerialization = {'CSV': {\"FileHeaderInfo\": \"Use\"}, 'CompressionType': 'NONE'},\n","        OutputSerialization = {'CSV': {}},\n","    )   \n","    \n","    event_stream = resp['Payload']\n","\n","    for event in event_stream:\n","        if 'Records' in event:\n","            data_in = StringIO(str(event['Records']['Payload'].decode(\"utf-8\")))\n","            df = pd.read_csv(data_in, header=None)\n","            return df\n","\n","    return None\n","```"]},{"cell_type":"markdown","metadata":{"id":"K8sFIQnuftEe"},"source":["```Python\n","# launch a query\n","sql = \"select temperature,play from s3object\"\n","df = query_bucket(sql, \"<bucket name>\", \"<file key>\")\n","print(df)\n","```"]},{"cell_type":"code","metadata":{"id":"3NobXoH7ftEe"},"source":[""],"execution_count":null,"outputs":[]}]}