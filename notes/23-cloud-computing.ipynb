{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preamble to be able to run notebooks in Jupyter and Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    import sys\n",
    "    \n",
    "    drive.mount('/content/drive')\n",
    "    notes_home = \"/content/drive/Shared drives/CSC310/notes/\"\n",
    "    user_home = \"/content/drive/My Drive/\"\n",
    "    \n",
    "    sys.path.insert(1,notes_home) # let the notebook access the notes folder\n",
    "    \n",
    "except ModuleNotFoundError:\n",
    "    notes_home = \"\" # running native Jupyter environment -- notes home is the same as the notebook\n",
    "    user_home = \"\"  # under Jupyter we assume the user directory is the same as the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud Computing\n",
    "\n",
    "**Definition**: Cloud computing is the on-demand availability of computer system resources, especially data storage and computing power, without direct active management by the user. Cloud computing relies on sharing of resources to achieve coherence and [economies of scale](https://en.wikipedia.org/wiki/Economies_of_scale).\n",
    "\n",
    "[-Wikipedia](https://en.wikipedia.org/wiki/Cloud_computing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Cloud_computing.svg/1280px-Cloud_computing.svg.png\" height=\"350\" width=\"500\">\n",
    "\n",
    "**Cloud computing metaphor**: the group of networked elements providing services need not be individually addressed or managed by users; instead, the entire provider-managed suite of hardware and software can be thought of as an **amorphous cloud**.\n",
    "\n",
    "Googles Colab Notebooks is an example of application based cloud computing (for that matter their whole suite of application falls into that category)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Software as a service (SaaS)](https://en.wikipedia.org/wiki/Cloud_computing#Software_as_a_service_(SaaS))\n",
    "    \n",
    "    **Definition**: The capability provided to the consumer is to use the provider's applications running on a cloud infrastructure. \n",
    "    <!-- The applications are accessible from various client devices through either a thin client interface, such as a web browser (e.g., web-based email), or a program interface. The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage, or even individual application capabilities, with the possible exception of limited user-specific application configuration settings. -->\n",
    "    \n",
    "    **Examples**: Google Docs and Colab Notebooks\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "* [Platform as a service (PaaS)](https://en.wikipedia.org/wiki/Cloud_computing#Platform_as_a_service_(PaaS))\n",
    "\n",
    "    **Definition**: The capability provided to the consumer is to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages, libraries, services, and tools supported by the provider. \n",
    "    <!-- The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, or storage, but has control over the deployed applications and possibly configuration settings for the application-hosting environment.-->\n",
    "    \n",
    "    **Examples**: AWS Sagemaker and S3\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "* [Infrastructure as a service (IaaS)](https://en.wikipedia.org/wiki/Cloud_computing#Infrastructure_as_a_service_(IaaS))\n",
    "\n",
    "    **Definition**: The consumer is able to deploy and run arbitrary software, which can include operating systems and applications and has control over operating systems, storage, and deployed applications.\n",
    "    \n",
    "    **Examples**: AWS and Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science in the Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dmhnzl5mp9mj6.cloudfront.net/bigdata_awsblog/images/White_paper_image1.PNG\" width=\"600\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cloud-based architecture of a data science processing pipeline taking advantage of AWS' IaaS.  All the components can be provisioned and configured in AWS console or through their DevOps API.  ([Source](https://aws.amazon.com/blogs/big-data/big-data-analytics-options-on-aws-updated-white-paper/))\n",
    "\n",
    "We will take a look at two components in the above diagram:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cloud-based Storage: [S3](https://aws.amazon.com/s3/) (component #3)\n",
    "    \n",
    "    Amazon Simple Storage Service (Amazon S3) is an object storage service that offers scalability, data availability, security, and performance.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "* Cloud-based Machine Learning: [Sagemaker](https://aws.amazon.com/sagemaker/) (component #5)\n",
    "    \n",
    "    Amazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models quickly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "\n",
    "If you have an AWS account here are two nice tutorials\n",
    "\n",
    "* [s3 tutorial](https://aws.amazon.com/getting-started/hands-on/backup-files-to-amazon-s3/)\n",
    "\n",
    "* [Jupyter/Sagemaker](https://aws.amazon.com/getting-started/hands-on/build-train-deploy-machine-learning-model-sagemaker/)\n",
    "\n",
    "We will be doing work in AWS Classrooms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "1. Goto the S3 console.\n",
    "1. Create a bucket.\n",
    "1. Upload the 'tennis-numeric.csv' file into your bucket.\n",
    "1. Using the SQL interface figure out what the average temperature is for the week. \n",
    "    * Make sure you ticked off the 'File has header row' box.  \n",
    "    * Query: select avg(cast(temperature as integer)) from s3object\n",
    "    * Note that you have to explicitly cast the temperature column as integer!\n",
    " \n",
    "1. Using the SQL interface figure out how often we play or not play tennis in that week.\n",
    "    * Query: select count(play) from s3object where cast(play as string) like '%yes%'\n",
    "    * Note that you have to use 'like' with wildcard characters '%' in order to match 'yes' in case there are \n",
    "        hidden characters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "1. Goto the Sagemaker notebooks console.\n",
    "1. Create a notebook instance and open it in the Jupyter console.\n",
    "1. Create a notebook to do the following:\n",
    "    1. Access your play tennis data set stored in S3.\n",
    "    1. Build a decision tree\n",
    "    1. Print the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code snippets will be useful for the above exercises\n",
    "\n",
    "Cut and paste them into your Sagemaker notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "# Accessing buckets for Machine Learning in Sagemaker\n",
    "\n",
    "import s3fs\n",
    "\n",
    "df = pd.read_csv('s3://<bucket-name>/<filename>.csv')\n",
    "df.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "import operator\n",
    "\n",
    "def tree_print(clf, X):\n",
    "    \"\"\"\n",
    "    Print the tree of a sklearn DecisionTreeClassifier\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : DecisionTreeClassifier - A tree that has already been fit.\n",
    "    X : The original training set\n",
    "    \"\"\"\n",
    "    tlevel = _tree_rprint('', clf, X.columns, clf.classes_)\n",
    "    print('<',end='')\n",
    "    for i in range(3*tlevel - 2):\n",
    "        print('-',end='')\n",
    "    print('>')\n",
    "    print('Tree Depth: ',tlevel)\n",
    "\n",
    "def _tree_rprint(kword, clf, features, labels, node_index=0, tlevel_index=0):\n",
    "    # Note: The DecisionTreeClassifier uses the Tree structure defined in:\n",
    "    # \t\tgithub.com/scikit-learn/scikit-learn/blob/master/sklearn/tree/_tree.pyx\n",
    "    #       it is an array based tree implementation:\n",
    "\n",
    "    # indent the nodes according to their tree level\n",
    "    for i in range(tlevel_index):\n",
    "        print('  |',end='')\n",
    "\n",
    "\t#  TODO: the following should use the TREE_LEAF constant defined in _tree.pyx\n",
    "\t#        instead of -1, not quite sure how to get at it from the tree user level\n",
    "    if clf.tree_.children_left[node_index] == -1:  # indicates leaf\n",
    "        print(kword, end=' ' if kword else '')\n",
    "        # get the majority label\n",
    "        count_list = clf.tree_.value[node_index, 0]\n",
    "        #lhh\n",
    "        #print(\"count list: {}\".format(count_list))\n",
    "        if len(count_list) == 1:\n",
    "            # regression problem\n",
    "            print(count_list[0])\n",
    "        else:\n",
    "            # get the majority label\n",
    "            max_index, max_value = max(enumerate(count_list), key=operator.itemgetter(1))\n",
    "            max_label = labels[max_index]\n",
    "            print(max_label)\n",
    "        return tlevel_index\n",
    "    \n",
    "    else:\n",
    "        # compute and print node label\n",
    "        feature = features[clf.tree_.feature[node_index]]\n",
    "        threshold = clf.tree_.threshold[node_index]\n",
    "        print(kword, end=' ' if kword else '')\n",
    "        print('if {} =< {}: '.format(feature, threshold))\n",
    "        # recurse down the children\n",
    "        left_index = clf.tree_.children_left[node_index]\n",
    "        right_index = clf.tree_.children_right[node_index]\n",
    "        ltlevel_index = _tree_rprint('then', clf, features, labels, left_index, tlevel_index+1)\n",
    "        rtlevel_index = _tree_rprint('else', clf, features, labels, right_index, tlevel_index+1)\n",
    "        # return the maximum depth of either one of the children\n",
    "        return max(ltlevel_index,rtlevel_index)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
