{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxWjbZeJfUo7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d35f344e-f6b8-4f3a-a90b-5e933ceabb6d"
      },
      "source": [
        "###### Set Up #####\n",
        "# verify our folder with the data and module assets is installed\n",
        "# if it is installed make sure it is the latest\n",
        "!test -e ds-assets && cd ds-assets && git pull && cd ..\n",
        "# if it is not installed clone it\n",
        "!test ! -e ds-assets && git clone https://github.com/IndraniMandal/ds-assets.git\n",
        "# point to the folder with the assets\n",
        "home = \"ds-assets/assets/\"\n",
        "import sys\n",
        "sys.path.append(home)      # add home folder to module search path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ds-assets'...\n",
            "remote: Enumerating objects: 205, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rtKYu9zfUpI"
      },
      "source": [
        "# Image Compression: Color Quantization using k-Means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs9K18XwfUpI"
      },
      "source": [
        "In computer graphics, **color quantization** is a process that reduces the number of distinct colors used in an image, usually with the intention that the new image should be as visually similar as possible to the original image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsFtgKnSfUpJ"
      },
      "source": [
        "An example image in 24-bit RGB color, <br>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e3/Dithering_example_undithered.png\">\n",
        "\n",
        "The same image reduced to a palette of 16 colors ,<br>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/48/Dithering_example_undithered_16color_palette.png\">\n",
        "\n",
        "The palette is chosen using the k-means algorithm in RGB color space,<br>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/3/3d/Rosa_Gold_Glow_2_small_noblue_color_space.png\" height=\"300\" width=\"300\">\n",
        "\n",
        "(source: [Wikipedia](https://en.wikipedia.org/wiki/Color_quantization))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXDqhqEDfUpJ"
      },
      "source": [
        "# A Worked Example\n",
        "\n",
        "Perform a color quantization of an image of Yellowstone, **reducing the number of colors required to show the image from 96,615\n",
        "unique colors to 8 colors**, while preserving the overall appearance quality as much as possible.\n",
        "\n",
        "Based on the [quantization example from SKlearn](https://scikit-learn.org/stable/auto_examples/cluster/plot_color_quantization.html#sphx-glr-auto-examples-cluster-plot-color-quantization-py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yKvq-vbfUpJ"
      },
      "source": [
        "import numpy as np # we need access to numpy arrays\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import to_hex\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah-YHE29fUpJ"
      },
      "source": [
        "# number of colors to use for quantization\n",
        "n_colors = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32G122XlfUpJ"
      },
      "source": [
        "## Image Data\n",
        "\n",
        "We load a JPEG image from our folder.  **Note**, the technique we present here will work with any JPEG image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBLR9l8rfUpK"
      },
      "source": [
        "# load the image\n",
        "img = plt.imread(home+\"yellowstone.jpg\")\n",
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation**: It is a 446x669 image with three integers describing the color at each pixel."
      ],
      "metadata": {
        "id": "c3__ZVv-Ymkv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA-o0jrWIgbz"
      },
      "source": [
        "type(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtGjz0EmfUpK"
      },
      "source": [
        "# take a look at the top-left pixel\n",
        "img[0,0,]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "wlzewzPufUpK"
      },
      "source": [
        "# We need to convert to float [0.0-1.0] for RGB representation otherwise\n",
        "# pyplot will complain\n",
        "#img = np.array(img, dtype=np.float64) / 255\n",
        "img = img / 255\n",
        "img[0,0,]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHpOAftUfUpK"
      },
      "source": [
        "# show the image\n",
        "plt.clf()\n",
        "plt.axis('off')\n",
        "plt.title('Yellowstone')\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHbxkaIIfUpL"
      },
      "source": [
        "## Training Data\n",
        "\n",
        "Turn the image into training data for our k-means algorithm.  We need to transform the 3D image structure into a 2D training dataset.\n",
        "The training set is simply a list of all the pixels in 3D RGB color space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEFEgVgwfUpL"
      },
      "source": [
        "# transform 3D image structure to a 2D numpy array for training the k-means model\n",
        "# by listing all pixels as a continuous list of color vectors\n",
        "\n",
        "w, h, d = img.shape\n",
        "assert d == 3\n",
        "\n",
        "# the array is now a list of color values: list of points/pixels in RGB space.\n",
        "pixels = np.reshape(img, (w * h, 3))\n",
        "pixels[:16,]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAFgTBGZfUpL"
      },
      "source": [
        "assert len(pixels) == w*h\n",
        "len(pixels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pItBNuUVOT_u"
      },
      "source": [
        "**Observation**: Our image has more than a quarter million pixels.  This is way too much data to train our k-means algorithm.  \n",
        "\n",
        "We sample the pixels data to create our training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EYq-H1tfUpL"
      },
      "source": [
        "# create a 1% sample of the data\n",
        "assert(len(pixels) > 1000) # make sure there is enough data\n",
        "\n",
        "sample_size = len(pixels)//100\n",
        "\n",
        "pixels_sample = shuffle(pixels, random_state=0)[:sample_size]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp4QYwoufUpM"
      },
      "source": [
        "# plot training data in RGB space\n",
        "plt.figure()\n",
        "ax = plt.axes(projection='3d')\n",
        "ax.scatter3D(pixels_sample[:,0],\n",
        "             pixels_sample[:,1],\n",
        "             pixels_sample[:,2],\n",
        "             c=pixels_sample);\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxrLYQs4fUpM"
      },
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idea is now to use clustering with k centroids to find the k most significant colors in the RGB space.\n",
        "\n",
        "First, let's take a look at this via the elbow method."
      ],
      "metadata": {
        "id": "ws72Ocq-gToB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from elbow import plot_elbow\n",
        "\n",
        "plot_elbow(pixels_sample, n=15)"
      ],
      "metadata": {
        "id": "hdShFk9Xgnz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation**: It is interesting to note that k=8 appears at the upper end of the elbow.  So chosing k=8 is very reasonable. A lower k would mean that we might lose significant color differentiation and a higher k means that we are introducing colors which potentially do not add much more color differentiation to the image."
      ],
      "metadata": {
        "id": "bLKdhETcg9a1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oW0WqomfUpM"
      },
      "source": [
        "# train the model with n_colors\n",
        "model = KMeans(n_clusters=n_colors,  # our 8 colors\n",
        "               n_init='auto',\n",
        "               random_state=0)\n",
        "model.fit(pixels_sample)\n",
        "\n",
        "# the cluster centers now represent the new colors\n",
        "centroid_pixels = model.cluster_centers_\n",
        "centroid_pixels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR0ngu-GfUpM"
      },
      "source": [
        "# plot the colors of the k-means model\n",
        "fig = plt.figure()\n",
        "ax = plt.axes(projection='3d')\n",
        "ax.scatter3D(centroid_pixels[:,0],\n",
        "             centroid_pixels[:,1],\n",
        "             centroid_pixels[:,2],\n",
        "             c=centroid_pixels)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tJ7peWEfUpN"
      },
      "source": [
        "### Build Compressed Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we map every pixel in our pixels array to our of our centroids.  In effect, we are replacing the pixel color with the corresponding centroid color."
      ],
      "metadata": {
        "id": "22PVkx99jk4Z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiHC3-TpfUpN"
      },
      "source": [
        "# map each pixel in our pixels array to a centroid\n",
        "pixel_centroid_labels = model.predict(pixels)\n",
        "\n",
        "# show a random sample of the centroid labels\n",
        "shuffle(pixel_centroid_labels)[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwAg2u-QfUpN"
      },
      "source": [
        "# create a new pixels array based on the color centroid\n",
        "new_pixels = np.zeros((w*h,3)) # initialize the new pixes with zeros\n",
        "\n",
        "# map the original pixels into new pixels based on the\n",
        "# assigned centroid RGB value\n",
        "for i in range(w*h):\n",
        "    new_pixels[i] = centroid_pixels[pixel_centroid_labels[i]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape the new pixel array into a new image with the same dimensions as the original image.\n",
        "new_img = np.reshape(new_pixels,(w,h,3))"
      ],
      "metadata": {
        "id": "lmRwnkvzket-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the new image\n",
        "plt.clf()\n",
        "plt.axis('off')\n",
        "plt.imshow(new_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iCyX1ep0mCIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation**: Nothing drastic happened to the image!"
      ],
      "metadata": {
        "id": "PeVrj7cJmRlR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVx06nVlfUpN"
      },
      "source": [
        "### Image Comparison\n",
        "\n",
        "Not only do we show the original and the compressed image but we also save them to files so we can look at the effect that color quantization has on image file size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1_MtVaVfUpN"
      },
      "source": [
        "# original image\n",
        "plt.clf()\n",
        "plt.axis('off')\n",
        "plt.title('Original image (96,615 colors)')\n",
        "plt.imshow(img)\n",
        "plt.savefig(\"original.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl_1l9sqfUpO"
      },
      "source": [
        "# quantized image\n",
        "plt.clf()\n",
        "plt.axis('off')\n",
        "plt.title('Quantized image ({} colors, K-Means)'.format(n_colors))\n",
        "plt.imshow(new_img)\n",
        "plt.savefig(\"compressed.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXTUBU19fUpO"
      },
      "source": [
        "The sizes of the files are shown in KBytes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NitDFf8EfUpO"
      },
      "source": [
        "!ls -s -k original.png\n",
        "!ls -s -k compressed.png"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}