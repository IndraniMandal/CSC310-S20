{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Learning Curves\n",
    "\n",
    "* It can be shown that *any model* can learn its training data perfectly - “memorize it”.  That is what the blue curve shows below. Any model can achieve a perfect score on the training data as long as it is allowed to be complex enough. Maximum complexity: the model has memorized the entire dataset.\n",
    "\n",
    "* But memorizing is not the same as learning inherent patterns and use those patterns to make predictions!  Memorization is extremely bad at predicting future outcomes.  See what happens to the red line below as the model starts to memorize the dataset -- the score actually falls!\n",
    "\n",
    "> Memorization does not generalize well!\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we train a model using *training data* and then apply the model to a *validation/test data set* then we obtain these following typical curves:\n",
    "\n",
    "<!-- ![model curves](assets/model-performance-curves.png) -->\n",
    "\n",
    "<img src=\"assets/model-performance-curves.png\"  height=\"200\" width=\"400\">\n",
    "\n",
    "Note: Validation data is data that the model has not seen yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Simply put:\n",
    "\n",
    "1. Undertrained models make a lot of errors on validation data because they have not learned any of the patterns yet.\n",
    "\n",
    "2. Overtrained models (models that have memorized their training data) make a lot of errors on validation because memorization is extremely bad at predicting the future outcomes.\n",
    "\n",
    "3. The best models make a trade-off between errors and recognizing important patterns. Notice that for the best models the training score is not 100%!\n",
    "\n",
    "> In order to find the best model we have to search its *parameter space* in order to find just the right complexity level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train and Test (Validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In order to simulate the fact that a model is not able to see all possible data points during training we split our training data into two parts:\n",
    "\n",
    "* Training data\n",
    "* Testing (validation) data\n",
    "\n",
    "We will train our model on the training data as before but we will now test the model performance on the testing data which the model has not seen yet.\n",
    "\n",
    "> That is, we force the model to make some generalizations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Decision Trees: Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from assets.treeviz import tree_print\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "# sklearn provides manipulation of training sets\n",
    "# here we do train/test split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The Iris Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# set up our sklearn data shape for the iris data\n",
    "df = pd.read_csv(\"assets/iris.csv\")\n",
    "X  = df.drop(['id','Species'],axis=1)\n",
    "y = df['Species']\n",
    "\n",
    "# split the data - 70% training 30% testing\n",
    "datasets = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=2)\n",
    "X_train, X_test, y_train, y_test = datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can recreate the results given by the learning curves above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Complexity Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if Petal.Width =< 0.800000011920929: \n",
      "  |then setosa\n",
      "  |else virginica\n",
      "<->\n",
      "Tree Depth:  1\n",
      "Train Accuracy: 0.6666666666666666\n",
      "Test Accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# set up the tree model object - limit the complexity to put us somewhere in the middle of the graph.\n",
    "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
    "\n",
    "# fit the model on the training set of data\n",
    "model.fit(X_train, y_train)\n",
    "tree_print(model,X)\n",
    "\n",
    "# Train results: evaluate the model on the testing set of data\n",
    "y_train_model = model.predict(X_train)\n",
    "print(\"Train Accuracy: {}\".format(accuracy_score(y_train, y_train_model)))\n",
    "\n",
    "# Test results: evaluate the model on the testing set of data\n",
    "y_test_model = model.predict(X_test)\n",
    "print(\"Test Accuracy: {}\".format(accuracy_score(y_test, y_test_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medium Complexity Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if Petal.Length =< 2.3499999046325684: \n",
      "  |then setosa\n",
      "  |else if Petal.Width =< 1.6500000953674316: \n",
      "  |  |then if Petal.Length =< 4.949999809265137: \n",
      "  |  |  |then versicolor\n",
      "  |  |  |else virginica\n",
      "  |  |else if Petal.Length =< 4.850000381469727: \n",
      "  |  |  |then virginica\n",
      "  |  |  |else virginica\n",
      "<------->\n",
      "Tree Depth:  3\n",
      "Train Accuracy: 0.9809523809523809\n",
      "Test Accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# set up the tree model object - limit the complexity to put us somewhere in the middle of the graph.\n",
    "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "\n",
    "# fit the model on the training set of data\n",
    "model.fit(X_train, y_train)\n",
    "tree_print(model,X)\n",
    "\n",
    "# Train results: evaluate the model on the testing set of data\n",
    "y_train_model = model.predict(X_train)\n",
    "print(\"Train Accuracy: {}\".format(accuracy_score(y_train, y_train_model)))\n",
    "\n",
    "# Test results: evaluate the model on the testing set of data\n",
    "y_test_model = model.predict(X_test)\n",
    "print(\"Test Accuracy: {}\".format(accuracy_score(y_test, y_test_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Complexity Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if Petal.Width =< 0.800000011920929: \n",
      "  |then setosa\n",
      "  |else if Petal.Width =< 1.6500000953674316: \n",
      "  |  |then if Petal.Length =< 4.949999809265137: \n",
      "  |  |  |then versicolor\n",
      "  |  |  |else if Petal.Width =< 1.5499999523162842: \n",
      "  |  |  |  |then virginica\n",
      "  |  |  |  |else versicolor\n",
      "  |  |else if Petal.Length =< 4.850000381469727: \n",
      "  |  |  |then if Sepal.Width =< 3.0999999046325684: \n",
      "  |  |  |  |then virginica\n",
      "  |  |  |  |else versicolor\n",
      "  |  |  |else virginica\n",
      "<---------->\n",
      "Tree Depth:  4\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# set up the tree model object - limit the complexity to put us somewhere in the middle of the graph.\n",
    "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=None)\n",
    "\n",
    "# fit the model on the training set of data\n",
    "model.fit(X_train, y_train)\n",
    "tree_print(model,X)\n",
    "\n",
    "# Train results: evaluate the model on the testing set of data\n",
    "y_train_model = model.predict(X_train)\n",
    "print(\"Train Accuracy: {}\".format(accuracy_score(y_train, y_train_model)))\n",
    "\n",
    "# Test results: evaluate the model on the testing set of data\n",
    "y_test_model = model.predict(X_test)\n",
    "print(\"Test Accuracy: {}\".format(accuracy_score(y_test, y_test_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wisconsin Breast Cancer Dataset\n",
    "\n",
    "The data set is available at <a href=\"https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\">UCI</a>.\n",
    "The data set describes benign and malignent tumors based on image measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>radius1</th>\n",
       "      <th>texture1</th>\n",
       "      <th>perimeter1</th>\n",
       "      <th>area1</th>\n",
       "      <th>smoothness1</th>\n",
       "      <th>compactness1</th>\n",
       "      <th>concavity1</th>\n",
       "      <th>concave_points1</th>\n",
       "      <th>symmetry1</th>\n",
       "      <th>...</th>\n",
       "      <th>texture3</th>\n",
       "      <th>perimeter3</th>\n",
       "      <th>area3</th>\n",
       "      <th>smoothness3</th>\n",
       "      <th>compactness3</th>\n",
       "      <th>concavity3</th>\n",
       "      <th>concave_points3</th>\n",
       "      <th>symmetry3</th>\n",
       "      <th>fractal_dimension3</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  radius1  texture1  perimeter1   area1  smoothness1  compactness1  \\\n",
       "0   1    17.99     10.38      122.80  1001.0      0.11840       0.27760   \n",
       "1   2    20.57     17.77      132.90  1326.0      0.08474       0.07864   \n",
       "2   3    19.69     21.25      130.00  1203.0      0.10960       0.15990   \n",
       "3   4    11.42     20.38       77.58   386.1      0.14250       0.28390   \n",
       "4   5    20.29     14.34      135.10  1297.0      0.10030       0.13280   \n",
       "\n",
       "   concavity1  concave_points1  symmetry1    ...      texture3  perimeter3  \\\n",
       "0      0.3001          0.14710     0.2419    ...         17.33      184.60   \n",
       "1      0.0869          0.07017     0.1812    ...         23.41      158.80   \n",
       "2      0.1974          0.12790     0.2069    ...         25.53      152.50   \n",
       "3      0.2414          0.10520     0.2597    ...         26.50       98.87   \n",
       "4      0.1980          0.10430     0.1809    ...         16.67      152.20   \n",
       "\n",
       "    area3  smoothness3  compactness3  concavity3  concave_points3  symmetry3  \\\n",
       "0  2019.0       0.1622        0.6656      0.7119           0.2654     0.4601   \n",
       "1  1956.0       0.1238        0.1866      0.2416           0.1860     0.2750   \n",
       "2  1709.0       0.1444        0.4245      0.4504           0.2430     0.3613   \n",
       "3   567.7       0.2098        0.8663      0.6869           0.2575     0.6638   \n",
       "4  1575.0       0.1374        0.2050      0.4000           0.1625     0.2364   \n",
       "\n",
       "   fractal_dimension3  Diagnosis  \n",
       "0             0.11890          M  \n",
       "1             0.08902          M  \n",
       "2             0.08758          M  \n",
       "3             0.17300          M  \n",
       "4             0.07678          M  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up our sklearn data shape for the iris data\n",
    "df = pd.read_csv(\"assets/wdbc.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: Diagnosis, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if our data set is balanced\n",
    "df['Diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X  = df.drop(['ID','Diagnosis'],axis=1)\n",
    "y = df['Diagnosis']\n",
    "\n",
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Complexity Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if perimeter3 =< 113.14999389648438: \n",
      "  |then B\n",
      "  |else M\n",
      "<->\n",
      "Tree Depth:  1\n",
      "Train Accuracy: 0.9396984924623115\n",
      "Test Accuracy: 0.8713450292397661\n"
     ]
    }
   ],
   "source": [
    "# set up the tree model object - limit the complexity to put us somewhere in the middle of the graph.\n",
    "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
    "\n",
    "# fit the model on the training set of data\n",
    "model.fit(X_train, y_train)\n",
    "tree_print(model,X)\n",
    "\n",
    "# Train results: evaluate the model on the testing set of data\n",
    "y_train_model = model.predict(X_train)\n",
    "print(\"Train Accuracy: {}\".format(accuracy_score(y_train, y_train_model)))\n",
    "\n",
    "# Test results: evaluate the model on the testing set of data\n",
    "y_test_model = model.predict(X_test)\n",
    "print(\"Test Accuracy: {}\".format(accuracy_score(y_test, y_test_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medium Complexity Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if perimeter3 =< 113.14999389648438: \n",
      "  |then if concave_points3 =< 0.15630000829696655: \n",
      "  |  |then if texture1 =< 21.434999465942383: \n",
      "  |  |  |then if perimeter3 =< 110.05000305175781: \n",
      "  |  |  |  |then B\n",
      "  |  |  |  |else B\n",
      "  |  |  |else if area3 =< 646.449951171875: \n",
      "  |  |  |  |then B\n",
      "  |  |  |  |else B\n",
      "  |  |else if texture3 =< 23.470001220703125: \n",
      "  |  |  |then B\n",
      "  |  |  |else M\n",
      "  |else if concavity1 =< 0.062425002455711365: \n",
      "  |  |then if texture1 =< 20.739999771118164: \n",
      "  |  |  |then if smoothness2 =< 0.003134500002488494: \n",
      "  |  |  |  |then M\n",
      "  |  |  |  |else B\n",
      "  |  |  |else M\n",
      "  |  |else M\n",
      "<---------->\n",
      "Tree Depth:  4\n",
      "Train Accuracy: 0.9798994974874372\n",
      "Test Accuracy: 0.9005847953216374\n"
     ]
    }
   ],
   "source": [
    "# set up the tree model object - limit the complexity to put us somewhere in the middle of the graph.\n",
    "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "\n",
    "# fit the model on the training set of data\n",
    "model.fit(X_train, y_train)\n",
    "tree_print(model,X)\n",
    "\n",
    "# Train results: evaluate the model on the testing set of data\n",
    "y_train_model = model.predict(X_train)\n",
    "print(\"Train Accuracy: {}\".format(accuracy_score(y_train, y_train_model)))\n",
    "\n",
    "# Test results: evaluate the model on the testing set of data\n",
    "y_test_model = model.predict(X_test)\n",
    "print(\"Test Accuracy: {}\".format(accuracy_score(y_test, y_test_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Complexity Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if perimeter3 =< 113.14999389648438: \n",
      "  |then if concave_points3 =< 0.15630000829696655: \n",
      "  |  |then if texture1 =< 21.434999465942383: \n",
      "  |  |  |then if perimeter3 =< 110.05000305175781: \n",
      "  |  |  |  |then B\n",
      "  |  |  |  |else if fractal_dimension3 =< 0.09629999846220016: \n",
      "  |  |  |  |  |then B\n",
      "  |  |  |  |  |else M\n",
      "  |  |  |else if area3 =< 646.449951171875: \n",
      "  |  |  |  |then B\n",
      "  |  |  |  |else if symmetry3 =< 0.2696000039577484: \n",
      "  |  |  |  |  |then if perimeter2 =< 5.482500076293945: \n",
      "  |  |  |  |  |  |then B\n",
      "  |  |  |  |  |  |else M\n",
      "  |  |  |  |  |else M\n",
      "  |  |else if texture3 =< 23.470001220703125: \n",
      "  |  |  |then B\n",
      "  |  |  |else M\n",
      "  |else if concavity1 =< 0.062425002455711365: \n",
      "  |  |then if texture1 =< 20.739999771118164: \n",
      "  |  |  |then if smoothness2 =< 0.003134500002488494: \n",
      "  |  |  |  |then M\n",
      "  |  |  |  |else B\n",
      "  |  |  |else M\n",
      "  |  |else M\n",
      "<---------------->\n",
      "Tree Depth:  6\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.9064327485380117\n"
     ]
    }
   ],
   "source": [
    "# set up the tree model object - limit the complexity to put us somewhere in the middle of the graph.\n",
    "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=None)\n",
    "\n",
    "# fit the model on the training set of data\n",
    "model.fit(X_train, y_train)\n",
    "tree_print(model,X)\n",
    "\n",
    "# Train results: evaluate the model on the testing set of data\n",
    "y_train_model = model.predict(X_train)\n",
    "print(\"Train Accuracy: {}\".format(accuracy_score(y_train, y_train_model)))\n",
    "\n",
    "# Test results: evaluate the model on the testing set of data\n",
    "y_test_model = model.predict(X_test)\n",
    "print(\"Test Accuracy: {}\".format(accuracy_score(y_test, y_test_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train and Test\n",
    "\n",
    "We have already seen that just using a training set for model evaluation does not work!\n",
    "\n",
    "Our solution was to split the training data into a training and a test/validation set.\n",
    "\n",
    "<img src=\"assets/train-test-data.png\" height=\"200\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "With that we get the typical performance curves that allow us to evaluate models more realistically.\n",
    "\n",
    "\n",
    "<img src=\"assets/model-performance-curves.png\"  height=\"200\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Problem!\n",
    "\n",
    "* Train-testing relies on randomly splitting the training data into two parts.\n",
    "\n",
    "* If this split just happens to be a ‘bad’ split your results might be biased,\n",
    "\n",
    "**Solution:** cross-validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cross-Validation\n",
    "\n",
    "* In cross-validation we switch the roles of the two sets\n",
    "* We evaluate the model on each trial and then take the average\n",
    "* This will eliminate a lot of the bias\n",
    "\n",
    "<img src=\"assets/2fold-xval.png\" height=\"200\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "BUT, what if is the split was really bad: e.g. one of the sets does not contain any examples of one of the classes.\n",
    "\n",
    "**Solution:** create more trials - *n-fold cross-validation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As a solution to a single bad split -- perform the split multiple times -- then train and test -- take the average\n",
    "\n",
    "Example: \n",
    "* 5-fold CV - split the training data into 5 splits (folds)\n",
    "* Use each fold as a test/validation set and the other folds as training set\n",
    "* Multiple splits - even if one is bad it will be balanced out by the others.\n",
    "\n",
    "<img src=\"assets/5fold-xval.png\" height=\"200\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracies: [ 0.93333333  0.96666667  0.9         0.86666667  1.        ]\n",
      "Accuracy: 0.9333333333333332\n"
     ]
    }
   ],
   "source": [
    "# cross-validation Iris\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "# grab cross validation code\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# get data\n",
    "df = pd.read_csv(\"assets/iris.csv\")\n",
    "X  = df.drop(['id','Species'],axis=1)\n",
    "y = df['Species']\n",
    "\n",
    "# set up the model\n",
    "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
    "\n",
    "# do the 5-fold cross validation\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(\"Fold Accuracies: {}\".format(scores))\n",
    "print(\"Accuracy: {}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracies: [ 0.90434783  0.91304348  0.95575221  0.9380531   0.95575221]\n",
      "Accuracy: 0.933389765294344\n"
     ]
    }
   ],
   "source": [
    "# cross-validation WDBC\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "# grab cross validation code\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# get data\n",
    "df = pd.read_csv(\"assets/wdbc.csv\")\n",
    "X  = df.drop(['ID','Diagnosis'],axis=1)\n",
    "y = df['Diagnosis']\n",
    "\n",
    "# set up the model\n",
    "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "\n",
    "# do the 5-fold cross validation\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(\"Fold Accuracies: {}\".format(scores))\n",
    "print(\"Accuracy: {}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Evaluation - the Grid Search\n",
    "\n",
    "Where did our model parameters come from in the above examples?  We searched for them!  Therefore:\n",
    "\n",
    "* Finding the best model involves searching for (hyper-)parameter values that give you the best testing/cross-validation accuracy.\n",
    "* This is usually referred to as the *grid search*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sklearn helps us do that efficiently:\n",
    "* Sklearn has a built-in grid search that can optimize the model parameters\n",
    "* The tree has two parameters: criterion and depth\n",
    "* The grid search will find the optimal value for both of these parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'criterion': 'gini', 'max_depth': 4}\n",
      "Best tree:\n",
      "if Petal.Width =< 0.800000011920929: \n",
      "  |then setosa\n",
      "  |else if Petal.Width =< 1.75: \n",
      "  |  |then if Petal.Length =< 4.949999809265137: \n",
      "  |  |  |then if Petal.Width =< 1.6500000953674316: \n",
      "  |  |  |  |then versicolor\n",
      "  |  |  |  |else virginica\n",
      "  |  |  |else if Petal.Width =< 1.5499999523162842: \n",
      "  |  |  |  |then virginica\n",
      "  |  |  |  |else versicolor\n",
      "  |  |else if Petal.Length =< 4.850000381469727: \n",
      "  |  |  |then if Sepal.Width =< 3.0999999046325684: \n",
      "  |  |  |  |then virginica\n",
      "  |  |  |  |else versicolor\n",
      "  |  |  |else virginica\n",
      "<---------->\n",
      "Tree Depth:  4\n",
      "Accuracy: 0.9933333333333333\n"
     ]
    }
   ],
   "source": [
    "# Grid search with cross-validation for iris dataset\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# get data\n",
    "df = pd.read_csv(\"assets/iris.csv\")\n",
    "X  = df.drop(['id','Species'],axis=1)\n",
    "y = df['Species']\n",
    "\n",
    "# setting up grid search\n",
    "model = model = tree.DecisionTreeClassifier()\n",
    "param_grid = {'max_depth': list(range(1,11)),\n",
    "              'criterion': ['entropy', 'gini']\n",
    "              }\n",
    "grid = GridSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "# performing grid search \n",
    "grid.fit(X,y)\n",
    "\n",
    "# print out what we found\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "# print out the best model\n",
    "print(\"Best tree:\")\n",
    "tree_print(grid.best_estimator_,X)\n",
    "\n",
    "# Get the accuracy\n",
    "# Evaluate the tree\n",
    "# predicting        \n",
    "predict_y = grid.best_estimator_.predict(X)\n",
    "\n",
    "# accuracy          \n",
    "print(\"Accuracy: {}\".format(accuracy_score(y, predict_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'criterion': 'entropy', 'max_depth': 4}\n",
      "Best tree:\n",
      "if perimeter3 =< 105.94999694824219: \n",
      "  |then if concave_points3 =< 0.1350499987602234: \n",
      "  |  |then if area2 =< 48.974998474121094: \n",
      "  |  |  |then if texture3 =< 30.145000457763672: \n",
      "  |  |  |  |then B\n",
      "  |  |  |  |else B\n",
      "  |  |  |else if concavity1 =< 0.028985001146793365: \n",
      "  |  |  |  |then M\n",
      "  |  |  |  |else B\n",
      "  |  |else if texture3 =< 27.575000762939453: \n",
      "  |  |  |then if symmetry3 =< 0.35785001516342163: \n",
      "  |  |  |  |then B\n",
      "  |  |  |  |else M\n",
      "  |  |  |else M\n",
      "  |else if perimeter3 =< 117.44999694824219: \n",
      "  |  |then if smoothness3 =< 0.13609999418258667: \n",
      "  |  |  |then if texture3 =< 25.670000076293945: \n",
      "  |  |  |  |then B\n",
      "  |  |  |  |else M\n",
      "  |  |  |else if area2 =< 16.19499969482422: \n",
      "  |  |  |  |then B\n",
      "  |  |  |  |else M\n",
      "  |  |else if fractal_dimension2 =< 0.001547000021673739: \n",
      "  |  |  |then if compactness1 =< 0.07845500111579895: \n",
      "  |  |  |  |then B\n",
      "  |  |  |  |else M\n",
      "  |  |  |else M\n",
      "<---------->\n",
      "Tree Depth:  4\n",
      "Accuracy: 0.984182776801406\n"
     ]
    }
   ],
   "source": [
    "# Grid search with cross-validation for wisconsin breast cancer dataset\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# get data\n",
    "df = pd.read_csv(\"assets/wdbc.csv\")\n",
    "X  = df.drop(['ID','Diagnosis'],axis=1)\n",
    "y = df['Diagnosis']\n",
    "\n",
    "# setting up grid search\n",
    "model = model = tree.DecisionTreeClassifier()\n",
    "param_grid = {'max_depth': list(range(1,11)),\n",
    "              'criterion': ['entropy', 'gini']\n",
    "              }\n",
    "grid = GridSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "# performing grid search \n",
    "grid.fit(X,y)\n",
    "\n",
    "# print out what we found\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "# print out the best model\n",
    "print(\"Best tree:\")\n",
    "tree_print(grid.best_estimator_,X)\n",
    "\n",
    "# Get the accuracy\n",
    "# Evaluate the tree\n",
    "# predicting        \n",
    "predict_y = grid.best_estimator_.predict(X)\n",
    "\n",
    "# accuracy          \n",
    "print(\"Accuracy: {}\".format(accuracy_score(y, predict_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Accuracy Reexamined\n",
    "\n",
    "Consider a classification problem with two classes, then we observe the following outcomes of a prediction of a suitable classification model:\n",
    "\n",
    ">true positive (TP) -- predicted positive coincides with actual positive\n",
    "\n",
    ">true negative (TN) -- predicted negative coincides with actual negative\n",
    "\n",
    ">false positive (FP), Type I error -- predicted positive but actual negative\n",
    "\n",
    ">false negative (FN), Type II error -- predicted negative but actual positive\n",
    "\n",
    "Two types of errors possible!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can arrange the predictions in a matrix form\n",
    "* Errors will show up as values outside the major diagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"assets/confusion2.png\" height=\"400\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Wisconsin Breast Cancer Data Set\n",
    "\n",
    "Let's apply everything we have learned so far: build the best model, and then evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'criterion': 'entropy', 'max_depth': 8}\n",
      "Best tree:\n",
      "if perimeter3 =< 105.94999694824219: \n",
      "  |then if concave_points3 =< 0.1350499987602234: \n",
      "  |  |then if area2 =< 48.974998474121094: \n",
      "  |  |  |then if texture3 =< 30.145000457763672: \n",
      "  |  |  |  |then B\n",
      "  |  |  |  |else if smoothness2 =< 0.0034664999693632126: \n",
      "  |  |  |  |  |then M\n",
      "  |  |  |  |  |else if radius3 =< 14.430000305175781: \n",
      "  |  |  |  |  |  |then B\n",
      "  |  |  |  |  |  |else if smoothness3 =< 0.13530001044273376: \n",
      "  |  |  |  |  |  |  |then B\n",
      "  |  |  |  |  |  |  |else M\n",
      "  |  |  |else if symmetry3 =< 0.20784999430179596: \n",
      "  |  |  |  |then M\n",
      "  |  |  |  |else B\n",
      "  |  |else if texture3 =< 27.575000762939453: \n",
      "  |  |  |then if symmetry3 =< 0.35785001516342163: \n",
      "  |  |  |  |then B\n",
      "  |  |  |  |else if area1 =< 318.29998779296875: \n",
      "  |  |  |  |  |then B\n",
      "  |  |  |  |  |else M\n",
      "  |  |  |else M\n",
      "  |else if perimeter3 =< 117.44999694824219: \n",
      "  |  |then if smoothness3 =< 0.13609999418258667: \n",
      "  |  |  |then if texture3 =< 25.670000076293945: \n",
      "  |  |  |  |then B\n",
      "  |  |  |  |else if area3 =< 871.7999877929688: \n",
      "  |  |  |  |  |then if concavity1 =< 0.10655000060796738: \n",
      "  |  |  |  |  |  |then B\n",
      "  |  |  |  |  |  |else M\n",
      "  |  |  |  |  |else M\n",
      "  |  |  |else if symmetry3 =< 0.2572999894618988: \n",
      "  |  |  |  |then B\n",
      "  |  |  |  |else M\n",
      "  |  |else if fractal_dimension2 =< 0.001547000021673739: \n",
      "  |  |  |then if smoothness2 =< 0.0031544999219477177: \n",
      "  |  |  |  |then M\n",
      "  |  |  |  |else B\n",
      "  |  |  |else M\n",
      "<------------------->\n",
      "Tree Depth:  7\n",
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "     M    B\n",
      "M  212    0\n",
      "B    0  357\n"
     ]
    }
   ],
   "source": [
    "# set up\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# get data \n",
    "df = pd.read_csv(\"assets/wdbc.csv\")\n",
    "\n",
    "# create our sklearn data\n",
    "X  = df.drop(['ID','Diagnosis'],axis=1)\n",
    "y = df['Diagnosis']\n",
    "\n",
    "# setting up grid search using 5-fold CV\n",
    "model = tree.DecisionTreeClassifier()\n",
    "param_grid = {'max_depth': list(range(1,11)),\n",
    "              'criterion': ['entropy', 'gini']\n",
    "              }\n",
    "grid = GridSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "# performing grid search \n",
    "null = grid.fit(X,y)\n",
    "\n",
    "# print out what we found\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "# print out the best model\n",
    "print(\"Best tree:\")\n",
    "tree_print(grid.best_estimator_,X)\n",
    "\n",
    "# Evaluate the tree\n",
    "# predicting        \n",
    "predict_y = grid.best_estimator_.predict(X)\n",
    "\n",
    "# accuracy          \n",
    "print(\"Accuracy: {}\".format(accuracy_score(y, predict_y)))\n",
    "\n",
    "# build the confusion matrix \n",
    "labels = ['M','B']\n",
    "cm = confusion_matrix(y, predict_y, labels=labels)\n",
    "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "print(\"Confusion Matrix:\\n{}\".format(cm_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Midterm \n",
    "\n",
    "The midterm is a data analysis project very similar to the projects you have done over the last few weeks.  Find a data set whose **features/independent variables** are all **numerical** and whose **target/dependent variable** is categorical (**only labels - no numbers**, maximum number of different kind of labels is five).  If you have doubts about your selected dataset contact me.  The data set has to be different from all the data sets you have studied so far and you cannot select a dataset that appears in the asset folder of the course notes.  \n",
    "\n",
    "You have to perform the following tasks on your selected data set:\n",
    "\n",
    "* preliminary data analysis (use describe and count to analyze basic statistics on your data set).  Briefly report your findings.\n",
    "* use visualization (especially scatter plots, histograms, and bar graphs) to explore your data set further. Report you findings.\n",
    "* Build decision tree models. Build the **best** possible decision tree model of your data using the techniques such as grid-search and cross-validation covered in class. \n",
    "* Print your best model using treeviz and compute its accuracy\n",
    "* Compute the confusion matrix and comment on type I and type II errors your model is committing and if you should be concerned about these errors.\n",
    "* Provide a brief interpretation of the model.  Does it provide any deeper insights or patterns?  Can you relate the  model to patterns you found in your data during visualization?\n",
    "\n",
    "The midterm is an **INDIVIDUAL** effort, that means each student has to select their own data set and write their own report.  No team work permitted.  Please submit both your notebook and your data set (perhaps as a zip file)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
