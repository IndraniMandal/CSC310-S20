{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3405,
     "status": "ok",
     "timestamp": 1708971122830,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "LlVbRD8lY5nI",
    "outputId": "40a3974e-f8f3-49df-ea70-b316144e4777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "###### Config #####\n",
    "import sys, os, platform\n",
    "if os.path.isdir(\"ds-assets\"):\n",
    "  !cd ds-assets && git pull\n",
    "else:\n",
    "  !git clone https://github.com/lutzhamel/ds-assets.git\n",
    "colab = True if 'google.colab' in os.sys.modules else False\n",
    "system = platform.system() # \"Windows\", \"Linux\", \"Darwin\"\n",
    "home = \"ds-assets/assets/\"\n",
    "sys.path.append(home)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook level imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dsutils\n",
    "np.set_printoptions(formatter={'float_kind':\"{:3.2f}\".format})\n",
    "from sklearn import tree\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "az04_f5PY5nQ"
   },
   "source": [
    "# Model Building and Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Br5Q9ND9Y5nR"
   },
   "source": [
    "Building models carries with it a **certain amount of uncertainty**.\n",
    "Recall that machine learning is an inductive activity: We learn from examples and try to generalize by creating patterns/hypotheses/theories. We use datasets that represent **samples** from much\n",
    "larger domains in order to learn.  Recall the \"black swan problem\" where the overall domain of swans contains both white \n",
    "and black swans.  But the white swans outnumber the black swans by a substantial margin and therefore, if we are not careful, most samples \"D\" drawn from\n",
    "the overall population \"X\" will only contain white swans as can be seen in the figure below,\n",
    "\n",
    "<center>\n",
    "<img \n",
    "  src=\"https://raw.githubusercontent.com/lutzhamel/ds-assets/main/assets/black-swans.png\"  \n",
    "  height=\"200\" \n",
    "  width=\"240\">\n",
    "</center>\n",
    "\n",
    "This means, if we learn from those samples we will come to the incorrect conclusion that \"all swans are white\".\n",
    "\n",
    "What this example illustrates is that the quality of our model is very much dependent on the quality \n",
    "of the data samples.  Unfortunately, in most cases the machine learning practitioner has no control over\n",
    "the construction of the data samples. \n",
    "This quality of the sample representation of the domain is a constant source of uncertainty when building models.  We can actually observe this uncertainty even in our simple iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(home+\"iris.csv\")\n",
    "X  = df.drop(['id','Species'],axis=1)\n",
    "y = df['Species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using train-test splits to build models and reporting the testing accuracy.  We do this five times randomly splitting the iris data into train and test folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0: 0.89\n",
      "Accuracy 1: 0.96\n",
      "Accuracy 2: 0.93\n",
      "Accuracy 3: 0.96\n",
      "Accuracy 4: 0.91\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "   model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
    "   (X_train, X_test, y_train, y_test) = \\\n",
    "      model_selection.train_test_split(X, \n",
    "                                       y, \n",
    "                                       train_size=0.7, \n",
    "                                       test_size=0.3)\n",
    "   model.fit(X_train, y_train)\n",
    "   y_test_model = model.predict(X_test)\n",
    "   print(\"Accuracy {}: {:3.2f}\"\n",
    "         .format(i,metrics.accuracy_score(y_test, y_test_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the impact the random splits have on the testing accuracy.  But we know this already.  What has changed is our perspective with respect to the source of this variation: **Each split can be seen as randomly sampling a train and a test set from the original domain of all iris flowers**. As we can see, some samples give rise to good models (98% accuracy) some samples not so much (87% accuracy).  Here we are directly observing the effects of the uncertainty due to the data samples.\n",
    "\n",
    "\n",
    "Interestingly enough we can observe this uncertainty also in the cross-validation approach although notice that the extreme highs and the extreme lows are no longer present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3039,
     "status": "ok",
     "timestamp": 1708971125866,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "GmnqrVMnY5nS",
    "outputId": "0f37d1c4-af0b-4c7e-ae99-5b871f429ead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy 0: 0.93\n",
      "Mean Accuracy 1: 0.93\n",
      "Mean Accuracy 2: 0.93\n",
      "Mean Accuracy 3: 0.95\n",
      "Mean Accuracy 4: 0.94\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "   model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
    "   mean_score = model_selection.cross_val_score(model, \n",
    "                                                X, \n",
    "                                                y, \n",
    "                                                cv=model_selection.KFold(n_splits=5,\n",
    "                                                                         shuffle=True)).mean()\n",
    "   print(\"Mean Accuracy {}: {:3.2f}\".format(i, mean_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8-tHIRMY5nT"
   },
   "source": [
    "As we saw above, this uncertainty reflects into our models. If our data is a poor representation of the domain then the models we construct using it will generalize poorly. If our  data is a good representation of the domain then we can expect that our model will generalize well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use **confidence intervals** in order to quantify the uncertainty discussed above in our model evaluations.\n",
    "\n",
    "First, let us define confidence intervals formally. Given a model accuracy, *acc*, then the confidence interval is defined as the probability *p* that our model accuracy *acc* lies between some lower bound *lb* and some upper bound *ub*,\n",
    "\n",
    "$$\n",
    "Pr(lb \\le acc \\le ub) = p.\n",
    "$$\n",
    "\n",
    "Paraphrasing this equation with *p = 95%*:\n",
    "\n",
    "> We are 95% percent sure that our model accuracy is not worse than *lb* and not better than *ub*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AU9ejtiY5nU"
   },
   "source": [
    "Ultimitely we are interested in the lower and upper bounds of the 95% confidence interval.  We can use the following formula to compute the bounds:\n",
    "\n",
    "$$ub = acc + 1.96 \\sqrt \\frac{acc (1 - acc)}{n}$$\n",
    "\n",
    "$$lb = acc - 1.96 \\sqrt \\frac{acc (1 - acc)}{n}$$\n",
    "\n",
    "Here, *n* is the number of observations in the testing dataset used to estimate *acc*. The constant 1.96 is called the *z-score* and expresses the fact that we are computing the 95% confidence interval.\n",
    "\n",
    "Notice that as we let $n \\rightarrow \\infty$ both the upper bound and the lower bound tend towards the accuracy.  That is, as we test the model on more and more testing points we become more and more confident that the given accuracy this the correct accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNpyW7qlY5nU"
   },
   "source": [
    "\n",
    "Let's do a simple example using the function `classification_confint`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1708971125866,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "a74qYZXmY5nV",
    "outputId": "46de4da7-a992-41c7-edcf-0172aa29544f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with confidence interval: 0.88 (0.82,0.94)\n"
     ]
    }
   ],
   "source": [
    "# assume the following\n",
    "observations = 100\n",
    "acc = .88\n",
    "\n",
    "# then\n",
    "lb,ub = dsutils.classification_confint(acc,observations)\n",
    "print('Accuracy with confidence interval: {} ({:3.2f},{:3.2f})'.format(acc,lb, ub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZrS6gvHY5nV"
   },
   "source": [
    "Now, let's do an actual example using our iris dataset.  We want to print out the testing accuracy together with it's 95% confidence interval. We construct a model with limited complexity and train and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9823,
     "status": "ok",
     "timestamp": 1708971135667,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "HjHjnvrV6CH9",
    "outputId": "57d4f48b-5961-44c8-bc59-3999b3771e1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with confidence interval: 0.93 (0.86, 1.00)\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion='entropy', \n",
    "                                    max_depth=2) # we limit the complexity of the model\n",
    "(X_train, X_test, y_train, y_test) = \\\n",
    "    model_selection.train_test_split(X, \n",
    "                                    y, \n",
    "                                    train_size=0.7, \n",
    "                                    test_size=0.3)\n",
    "model.fit(X_train, y_train)\n",
    "y_test_model = model.predict(X_test)\n",
    "\n",
    "# compute the accuracy of optimal classifier\n",
    "acc = metrics.accuracy_score(y_test, y_test_model)\n",
    "observations = X_test.shape[0]\n",
    "lb,ub = dsutils.classification_confint(acc,observations)\n",
    "\n",
    "# print accuracy\n",
    "print(\"Accuracy with confidence interval: {:3.2f} ({:3.2f}, {:3.2f})\".format(acc, lb, ub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxsPRGorY5nW"
   },
   "source": [
    "# Regression Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tL0IOclY5nW"
   },
   "source": [
    "When performing regression we use the $R^2$ score to examine the quality of our models.  Given that we only use a small training dataset for fitting the model compared to the rest of the data universe it is only natural to ask what the 95% confidence interval for this score might be.  We have a formula for that -- it is not as straight forward as the confidence interval for classification,\n",
    "\n",
    "$$lb = R^2 - 2\\sqrt{\\frac{4R^{2}(1-R^{2})^{2}(n-k-1)^{2}}{(n^2 - 1)(n+3)}}$$\n",
    "\n",
    "$$ub = R^2 + 2\\sqrt{\\frac{4R^{2}(1-R^{2})^{2}(n-k-1)^{2}}{(n^2 - 1)(n+3)}}$$\n",
    "\n",
    "Here, *n* is the number of observations in the validation/testing dataset and *k* is the number of independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1708971135668,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "2-YDIVcCY5nX",
    "outputId": "b8c4b383-fc04-484b-ff87-2e925c955d09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score with confidence interval: 0.75 (0.67, 0.83)\n"
     ]
    }
   ],
   "source": [
    "# assume the following\n",
    "rs_score = .75\n",
    "observations = 100\n",
    "variables = 4 # independent variables\n",
    "\n",
    "# then\n",
    "lb,ub = dsutils.regression_confint(rs_score, observations, variables)\n",
    "print(\"R^2 Score with confidence interval: {:3.2f} ({:3.2f}, {:3.2f})\".format(rs_score,lb,ub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzIOt6KJY5nX"
   },
   "source": [
    "Let's look at an actual regression problem and compute the $R^2$ score and it's 95% confidence interval. We will use the cars problem from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 982,
     "status": "ok",
     "timestamp": 1708971136636,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "bfrHjJj5nUKb",
    "outputId": "7ff9d3fb-94b8-4a24-e149-118f7d52346e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score with confidence interval: 0.76 (0.66, 0.87)\n"
     ]
    }
   ],
   "source": [
    "# get our dataset\n",
    "cars_df = pd.read_csv(home+\"cars.csv\")\n",
    "\n",
    "# build model object\n",
    "model = tree.DecisionTreeRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': list(range(1,11)), # search 1..10\n",
    "    }\n",
    "grid = model_selection.GridSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "# performing grid search\n",
    "grid.fit(cars_df[['speed']],cars_df[['dist']])\n",
    "\n",
    "# R^2 score\n",
    "rs_score = grid.best_estimator_.score(cars_df[['speed']],cars_df[['dist']])\n",
    "observations = cars_df.shape[0]\n",
    "variables = 1\n",
    "lb,ub = dsutils.regression_confint(rs_score, observations, variables)\n",
    "\n",
    "# print out R^2 score with its 95% confidence interval\n",
    "print(\"R^2 Score with confidence interval: {:3.2f} ({:3.2f}, {:3.2f})\".format(rs_score,lb,ub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcIGuoRqY5nY"
   },
   "source": [
    "# Statistical Significance\n",
    "\n",
    "Besides giving us an idea of the uncertainty of our model the 95% confidence intervals also have something to say about the significance of scores of different models.  That is, if the confidence intervals overlap then the difference in model performance of two different models on the same dataset is **not statistically significant**.\n",
    "\n",
    "Consider the following,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1708971136636,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "uVH7oXjUY5nY",
    "outputId": "e8fcbe55-5b01-4e21-96ab-1403c934654f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88 (0.82,0.94)\n",
      "Accuracy: 0.92 (0.87,0.97)\n"
     ]
    }
   ],
   "source": [
    "observations = 100\n",
    "\n",
    "# assume first classifier\n",
    "acc1 = .88  # accuracy of first classifier\n",
    "lb1,ub1 = dsutils.classification_confint(acc1,observations)\n",
    "print('Accuracy: {} ({:3.2f},{:3.2f})'.format(acc1,lb1, ub1))\n",
    "\n",
    "# assume second classifier\n",
    "acc2 = .92  # accuracy of second classifier\n",
    "lb2,ub2 = dsutils.classification_confint(acc2,observations)\n",
    "print('Accuracy: {} ({:3.2f},{:3.2f})'.format(acc2,lb2, ub2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaUTqEY9Y5nZ"
   },
   "source": [
    "Even though the second classifier has a better raw accuracy when we look at the confidence intervals of the two classifiers we see that they overlap.  Here we see that the first classifier could potentially have an accuracy of .94 (even better than the raw accuracy of the second classifier).  Furthermore, the confidence interval of the second classifier tells us that that classifier could potentially have an accuracy of .87 which is worse than the raw accuracy of the first classifier.  For this reason we say that the difference in accuracy of two classifiers is not statistically significant if their confidence intervals overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7zuIKNZklPm"
   },
   "source": [
    "## A Worked Example\n",
    "\n",
    "Here we use a real-world dataset that tries to predict the sex of abolone given a set of parameters.\n",
    "First we will construct the optimal model and then we construct a tree with minimal complexity for the same data set and compare the performances using statistical significance.\n",
    "\n",
    "The optimal tree first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5246,
     "status": "ok",
     "timestamp": 1708971141879,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "mrnvMlNFkjDM",
    "outputId": "20509d94-02e1-4ab1-bde5-8156bd8d4891"
   },
   "outputs": [],
   "source": [
    "# get the abalone data\n",
    "df = pd.read_csv(home+\"abalone.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic descriptive statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4177, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sex  length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   shell_weight  rings  \n",
       "0         0.150     15  \n",
       "1         0.070      7  \n",
       "2         0.210      9  \n",
       "3         0.155     10  \n",
       "4         0.055      7  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.523992</td>\n",
       "      <td>0.407881</td>\n",
       "      <td>0.139516</td>\n",
       "      <td>0.828742</td>\n",
       "      <td>0.359367</td>\n",
       "      <td>0.180594</td>\n",
       "      <td>0.238831</td>\n",
       "      <td>9.933684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.120093</td>\n",
       "      <td>0.099240</td>\n",
       "      <td>0.041827</td>\n",
       "      <td>0.490389</td>\n",
       "      <td>0.221963</td>\n",
       "      <td>0.109614</td>\n",
       "      <td>0.139203</td>\n",
       "      <td>3.224169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.441500</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.799500</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>1.153000</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.329000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>2.825500</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length     diameter       height  whole_weight  shucked_weight  \\\n",
       "count  4177.000000  4177.000000  4177.000000   4177.000000     4177.000000   \n",
       "mean      0.523992     0.407881     0.139516      0.828742        0.359367   \n",
       "std       0.120093     0.099240     0.041827      0.490389        0.221963   \n",
       "min       0.075000     0.055000     0.000000      0.002000        0.001000   \n",
       "25%       0.450000     0.350000     0.115000      0.441500        0.186000   \n",
       "50%       0.545000     0.425000     0.140000      0.799500        0.336000   \n",
       "75%       0.615000     0.480000     0.165000      1.153000        0.502000   \n",
       "max       0.815000     0.650000     1.130000      2.825500        1.488000   \n",
       "\n",
       "       viscera_weight  shell_weight        rings  \n",
       "count     4177.000000   4177.000000  4177.000000  \n",
       "mean         0.180594      0.238831     9.933684  \n",
       "std          0.109614      0.139203     3.224169  \n",
       "min          0.000500      0.001500     1.000000  \n",
       "25%          0.093500      0.130000     8.000000  \n",
       "50%          0.171000      0.234000     9.000000  \n",
       "75%          0.253000      0.329000    11.000000  \n",
       "max          0.760000      1.005000    29.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['sex']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "M      1528\n",
       "I      1342\n",
       "F      1307\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['sex']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct our data matrices\n",
    "X  = df.drop(columns=['sex'])\n",
    "y = df[['sex']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct our optimal tree first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of optimal classifier with confidence interval: 0.59 (0.57, 0.60)\n"
     ]
    }
   ],
   "source": [
    "# optimal tree\n",
    "# setting up grid search\n",
    "model = tree.DecisionTreeClassifier(random_state=1)\n",
    "param_grid = {\n",
    "    'max_depth': list(range(1,11)), # search 1..10\n",
    "    'criterion': ['entropy', 'gini', 'log_loss']\n",
    "    }\n",
    "grid = model_selection.GridSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "# performing grid search\n",
    "grid.fit(X,y)\n",
    "predict_y = grid.best_estimator_.predict(X)\n",
    "\n",
    "# compute the accuracy of optimal classifier\n",
    "acc = metrics.accuracy_score(y, predict_y)\n",
    "observations = X.shape[0]\n",
    "lb,ub = dsutils.classification_confint(acc,observations)\n",
    "\n",
    "# print accuracy\n",
    "print(\"Accuracy of optimal classifier with confidence interval: {:3.2f} ({:3.2f}, {:3.2f})\"\n",
    "      .format(acc, lb, ub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZtiugV8lVOc"
   },
   "source": [
    "Now we construct the minimal tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1708971142076,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "-zXdGYhjlcsx",
    "outputId": "d5a6fef5-60af-4aa2-9f83-04be8575de8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of minimal classifier with confidence interval: 0.53 (0.52, 0.55)\n"
     ]
    }
   ],
   "source": [
    "# minimal complexity tree: depth 2\n",
    "# create our model object\n",
    "model = tree.DecisionTreeClassifier(criterion='entropy', \n",
    "                                    max_depth=2, \n",
    "                                    random_state=1)\n",
    "\n",
    "# train\n",
    "model.fit(X,y)\n",
    "predict_y = model.predict(X)\n",
    "\n",
    "# compute the accuracy of minimal classifier\n",
    "acc = metrics.accuracy_score(y, predict_y)\n",
    "observations = X.shape[0]\n",
    "lb,ub = dsutils.classification_confint(acc,observations)\n",
    "\n",
    "# print accuracy\n",
    "print(\"Accuracy of minimal classifier with confidence interval: {:3.2f} ({:3.2f}, {:3.2f})\"\n",
    "      .format(acc, lb, ub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWjE01FhmF6V"
   },
   "source": [
    "**Observation**: The confidence intervals are not overlapping, therefore **the performance difference is statistically significant**! That means the optimal model indeed performs better than the minimal tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNDtX6Zumcm5"
   },
   "source": [
    "# Project\n",
    "\n",
    "Please see BrightSpace."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
