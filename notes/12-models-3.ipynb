{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3405,
     "status": "ok",
     "timestamp": 1708971122830,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "LlVbRD8lY5nI",
    "outputId": "40a3974e-f8f3-49df-ea70-b316144e4777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "###### Config #####\n",
    "import sys, os, platform\n",
    "if os.path.isdir(\"ds-assets\"):\n",
    "  !cd ds-assets && git pull\n",
    "else:\n",
    "  !git clone https://github.com/lutzhamel/ds-assets.git\n",
    "colab = True if 'google.colab' in os.sys.modules else False\n",
    "system = platform.system() # \"Windows\", \"Linux\", \"Darwin\"\n",
    "home = \"ds-assets/assets/\"\n",
    "sys.path.append(home)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook level imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dsutils\n",
    "np.set_printoptions(formatter={'float_kind':\"{:3.2f}\".format})\n",
    "from sklearn import tree\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "az04_f5PY5nQ"
   },
   "source": [
    "# Model Building and Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Br5Q9ND9Y5nR"
   },
   "source": [
    "Building models carries with it a **certain amount of uncertainty**.\n",
    "Recall that machine learning is an inductive activity: We learn from examples and try to generalize into patterns/hypotheses/theories. In general, our examples are datasets that represent a **sample** from a much\n",
    "larger domain.  Recall the \"black swan problem\" where the overall domain of swans contains both white \n",
    "and black swans.  But the white swans outnumber the black swans by a substantial margin and therefore most samples \"D\" drawn from\n",
    "the overall population \"X\" will only contain white swans as can be seen in the figure below,\n",
    "\n",
    "<center>\n",
    "<img \n",
    "  src=\"https://raw.githubusercontent.com/lutzhamel/ds-assets/main/assets/black-swans.png\"  \n",
    "  height=\"200\" \n",
    "  width=\"250\">\n",
    "</center>\n",
    "\n",
    "This means, if we learn from the samples we will come to the conclusion that \"all swans are white\".\n",
    "\n",
    "What this example illustrates is that the quality of our model is very much dependent on the quality \n",
    "of the learning data.  Unfortunately, in most cases the machine learning practitioner has no control over\n",
    "the construction of the data sample. For instance, in a bank application it is simply the database of all the customers of that particular bank which represents a sample of all bank customers of all banks worldwide. \n",
    "\n",
    "This sample representation of the domain is one source of uncertaintly when building models.  Another source of ucertaintly is the construction of training and testing sets from the sample.  In the previous notebook we discussed techniques that minimize the impact of those splits but a certain amount of uncertainty always remains.\n",
    "\n",
    "Consider the following examples that use the iris dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(home+\"iris.csv\")\n",
    "X  = df.drop(['id','Species'],axis=1)\n",
    "y = df['Species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using train-test splits to build models,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0: 0.98\n",
      "Accuracy 1: 0.91\n",
      "Accuracy 2: 0.89\n",
      "Accuracy 3: 0.96\n",
      "Accuracy 4: 0.89\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "   model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
    "   (X_train, X_test, y_train, y_test) = \\\n",
    "      model_selection.train_test_split(X, \n",
    "                                       y, \n",
    "                                       train_size=0.7, \n",
    "                                       test_size=0.3)\n",
    "   model.fit(X_train, y_train)\n",
    "   y_test_model = model.predict(X_test)\n",
    "   print(\"Accuracy {}: {:3.2f}\"\n",
    "         .format(i,metrics.accuracy_score(y_test, y_test_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the way we split has a huge impact on the model quality.  But we knew that already and therefore we used the cross-validation approach,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3039,
     "status": "ok",
     "timestamp": 1708971125866,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "GmnqrVMnY5nS",
    "outputId": "0f37d1c4-af0b-4c7e-ae99-5b871f429ead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy 0: 0.91\n",
      "Mean Accuracy 1: 0.95\n",
      "Mean Accuracy 2: 0.94\n",
      "Mean Accuracy 3: 0.92\n",
      "Mean Accuracy 4: 0.92\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "   model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
    "   mean_score = model_selection.cross_val_score(model, \n",
    "                                                X, \n",
    "                                                y, \n",
    "                                                cv=model_selection.KFold(n_splits=5,\n",
    "                                                                         shuffle=True)).mean()\n",
    "   print(\"Mean Accuracy {}: {:3.2f}\".format(i, mean_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if with the cross-validation approach we still see a substantial variation in the observed accuracies, perhaps not as drastic as in the test-split approach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8-tHIRMY5nT"
   },
   "source": [
    "This uncertainty reflects into our model evaluation. If our training data is a poor representation of the data universe then the models we construct using it will generalize poorly to the rest of the data universe. If our training data is a good representation of the data universe then we can expect that our model will generalize well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use **confidence intervals** in order to quantify the uncertainties discussed above in our analyses.\n",
    "\n",
    "First, let us define confidence intervals formally. Given a model accuracy, *acc*, then the confidence interval is defined as the probability *p* that our model accuracy *acc* lies between some lower bound *lb* and some upper bound *ub*,\n",
    "\n",
    "$$\n",
    "Pr(lb \\le acc \\le ub) = p.\n",
    "$$\n",
    "\n",
    "Paraphrasing this equation with *p = 95%*:\n",
    "\n",
    "> We are 95% percent sure that our model accuracy is not worse than *lb* and not better than *ub*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AU9ejtiY5nU"
   },
   "source": [
    "Ultimitely we are interested in the lower and upper bounds of the 95% confidence interval.  We can use the following formula to compute the bounds:\n",
    "\n",
    "$$ub = acc + 1.96 \\sqrt \\frac{acc (1 - acc)}{n}$$\n",
    "\n",
    "$$lb = acc - 1.96 \\sqrt \\frac{acc (1 - acc)}{n}$$\n",
    "\n",
    "Here, *n* is the number of observations in the testing dataset used to estimate *acc*. The constant 1.96 is called the *z-score* and expresses the fact that we are computing the 95% confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNpyW7qlY5nU"
   },
   "source": [
    "\n",
    "Let's do a simple example using the function `classification_confint`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1708971125866,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "a74qYZXmY5nV",
    "outputId": "46de4da7-a992-41c7-edcf-0172aa29544f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with confidence interval: 0.88 (0.82,0.94)\n"
     ]
    }
   ],
   "source": [
    "# assume the following\n",
    "observations = 100\n",
    "acc = .88\n",
    "\n",
    "# then\n",
    "lb,ub = dsutils.classification_confint(acc,observations)\n",
    "print('Accuracy with confidence interval: {} ({:3.2f},{:3.2f})'.format(acc,lb, ub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZrS6gvHY5nV"
   },
   "source": [
    "Now, let's do an actual example using our iris dataset.  We want to print out the testing accuracy together with it's 95% confidence interval. We construct a model with limited complexity and train and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9823,
     "status": "ok",
     "timestamp": 1708971135667,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "HjHjnvrV6CH9",
    "outputId": "57d4f48b-5961-44c8-bc59-3999b3771e1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with confidence interval: 0.96 (0.90, 1.00)\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
    "(X_train, X_test, y_train, y_test) = \\\n",
    "    model_selection.train_test_split(X, \n",
    "                                    y, \n",
    "                                    train_size=0.7, \n",
    "                                    test_size=0.3)\n",
    "model.fit(X_train, y_train)\n",
    "y_test_model = model.predict(X_test)\n",
    "\n",
    "# compute the accuracy of optimal classifier\n",
    "acc = metrics.accuracy_score(y_test, y_test_model)\n",
    "observations = X_test.shape[0]\n",
    "lb,ub = dsutils.classification_confint(acc,observations)\n",
    "\n",
    "# print accuracy\n",
    "print(\"Accuracy with confidence interval: {:3.2f} ({:3.2f}, {:3.2f})\".format(acc, lb, ub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxsPRGorY5nW"
   },
   "source": [
    "# Regression Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tL0IOclY5nW"
   },
   "source": [
    "When performing regression we use the $R^2$ score to examine the quality of our models.  Given that we only use a small training dataset for fitting the model compared to the rest of the data universe it is only natural to ask what the 95% confidence interval for this score might be.  We have a formula for that -- it is not as straight forward as the confidence interval for classification,\n",
    "\n",
    "$$lb = R^2 - 2\\sqrt{\\frac{4R^{2}(1-R^{2})^{2}(n-k-1)^{2}}{(n^2 - 1)(n+3)}}$$\n",
    "\n",
    "$$ub = R^2 + 2\\sqrt{\\frac{4R^{2}(1-R^{2})^{2}(n-k-1)^{2}}{(n^2 - 1)(n+3)}}$$\n",
    "\n",
    "Here, *n* is the number of observations in the validation/testing dataset and *k* is the number of independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1708971135668,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "2-YDIVcCY5nX",
    "outputId": "b8c4b383-fc04-484b-ff87-2e925c955d09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score with confidence interval: 0.75 (0.67, 0.83)\n"
     ]
    }
   ],
   "source": [
    "# assume the following\n",
    "rs_score = .75\n",
    "observations = 100\n",
    "variables = 4 # independent variables\n",
    "\n",
    "# then\n",
    "lb,ub = dsutils.regression_confint(rs_score, observations, variables)\n",
    "print(\"R^2 Score with confidence interval: {:3.2f} ({:3.2f}, {:3.2f})\".format(rs_score,lb,ub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzIOt6KJY5nX"
   },
   "source": [
    "Let's look at an actual regression problem and compute the $R^2$ score and it's 95% confidence interval. We will use the cars problem from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 982,
     "status": "ok",
     "timestamp": 1708971136636,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "bfrHjJj5nUKb",
    "outputId": "7ff9d3fb-94b8-4a24-e149-118f7d52346e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score with confidence interval: 0.76 (0.66, 0.87)\n"
     ]
    }
   ],
   "source": [
    "# get our dataset\n",
    "cars_df = pd.read_csv(home+\"cars.csv\")\n",
    "\n",
    "# build model object\n",
    "model = tree.DecisionTreeRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': list(range(1,11)), # search 1..10\n",
    "    }\n",
    "grid = model_selection.GridSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "# performing grid search\n",
    "grid.fit(cars_df[['speed']],cars_df[['dist']])\n",
    "\n",
    "# R^2 score\n",
    "rs_score = grid.best_estimator_.score(cars_df[['speed']],cars_df[['dist']])\n",
    "observations = cars_df.shape[0]\n",
    "variables = 1\n",
    "lb,ub = dsutils.regression_confint(rs_score, observations, variables)\n",
    "\n",
    "# print out R^2 score with its 95% confidence interval\n",
    "print(\"R^2 Score with confidence interval: {:3.2f} ({:3.2f}, {:3.2f})\".format(rs_score,lb,ub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcIGuoRqY5nY"
   },
   "source": [
    "# Statistical Significance\n",
    "\n",
    "Besides giving us an idea of the uncertainty of our model the 95% confidence intervals also have something to say about the significance of scores of different models.  That is, if the confidence intervals overlap then the difference in model performance of two different models on the same dataset is not statistically significant.\n",
    "\n",
    "Consider the following,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1708971136636,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "uVH7oXjUY5nY",
    "outputId": "e8fcbe55-5b01-4e21-96ab-1403c934654f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88 (0.82,0.94)\n",
      "Accuracy: 0.92 (0.87,0.97)\n"
     ]
    }
   ],
   "source": [
    "observations = 100\n",
    "\n",
    "# assume first classifier\n",
    "acc1 = .88\n",
    "lb1,ub1 = dsutils.classification_confint(acc1,observations)\n",
    "print('Accuracy: {} ({:3.2f},{:3.2f})'.format(acc1,lb1, ub1))\n",
    "\n",
    "# assume second classifier\n",
    "acc2 = .92\n",
    "lb2,ub2 = dsutils.classification_confint(acc2,observations)\n",
    "print('Accuracy: {} ({:3.2f},{:3.2f})'.format(acc2,lb2, ub2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaUTqEY9Y5nZ"
   },
   "source": [
    "Even though the second classifier has a better raw accuracy when we look at the confidence intervals of the two classifiers we see that they overlap.  Here we see that the first classifier could potentially have an accuracy of .94 (even better than the raw accuracy of the second classifier).  Furthermore, the confidence interval of the second classifier tells us that that classifier could potentially have an accuracy of .87 which is worse than the raw accuracy of the first classifier.  For this reason we say that the difference in accuracy of two classifiers is not statistically significant if their confidence intervals overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7zuIKNZklPm"
   },
   "source": [
    "## A Worked Example\n",
    "\n",
    "First we will construct the optimal model for the abalone data set which is the same code as we have seen above and then we construct a minimal tree for the same data set and compare the performances using statistical significance.\n",
    "\n",
    "The optimal tree first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5246,
     "status": "ok",
     "timestamp": 1708971141879,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "mrnvMlNFkjDM",
    "outputId": "20509d94-02e1-4ab1-bde5-8156bd8d4891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of optimal classifier with confidence interval: 0.59 (0.57, 0.60)\n"
     ]
    }
   ],
   "source": [
    "# Grid search with cross-validation for abalone dataset\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# get data\n",
    "df = pd.read_csv(home+\"abalone.csv\")\n",
    "X  = df.drop(columns=['sex'])\n",
    "y = df[['sex']]\n",
    "\n",
    "# setting up grid search\n",
    "model = tree.DecisionTreeClassifier(random_state=1)\n",
    "param_grid = {\n",
    "    'max_depth': list(range(1,11)), # search 1..10\n",
    "    'criterion': ['entropy', 'gini', 'log_loss']\n",
    "    }\n",
    "grid = GridSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "# performing grid search\n",
    "grid.fit(X,y)\n",
    "\n",
    "# compute the accuracy of optimal classifier\n",
    "predict_y = grid.best_estimator_.predict(X)\n",
    "acc = accuracy_score(y, predict_y)\n",
    "observations = X.shape[0]\n",
    "lb,ub = dsutils.classification_confint(acc,observations)\n",
    "\n",
    "# print accuracy\n",
    "print(\"Accuracy of optimal classifier with confidence interval: {:3.2f} ({:3.2f}, {:3.2f})\".format(acc, lb, ub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZtiugV8lVOc"
   },
   "source": [
    "Now we construct the minimal tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1708971142076,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "-zXdGYhjlcsx",
    "outputId": "d5a6fef5-60af-4aa2-9f83-04be8575de8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of minimal classifier with confidence interval: 0.53 (0.52, 0.55)\n"
     ]
    }
   ],
   "source": [
    "# create our model object\n",
    "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=2, random_state=1)\n",
    "\n",
    "# train\n",
    "model.fit(X,y)\n",
    "\n",
    "# compute the accuracy of minimal classifier\n",
    "predict_y = model.predict(X)\n",
    "acc = accuracy_score(y, predict_y)\n",
    "observations = X.shape[0]\n",
    "lb,ub = dsutils.classification_confint(acc,observations)\n",
    "\n",
    "# print accuracy\n",
    "print(\"Accuracy of minimal classifier with confidence interval: {:3.2f} ({:3.2f}, {:3.2f})\".format(acc, lb, ub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWjE01FhmF6V"
   },
   "source": [
    "**Observation**: The confidence intervals are not overlapping, therefore the performance difference is statistically significant!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNDtX6Zumcm5"
   },
   "source": [
    "# Project\n",
    "\n",
    "Please see BrightSpace."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
