{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "12-models-3.5.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IndraniMandal/CSC310-S20/blob/master/12_models_3_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B8hUcg-QP3a",
        "colab_type": "text"
      },
      "source": [
        "# Classification Confidence Intervals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWk5RDxqQP3g",
        "colab_type": "text"
      },
      "source": [
        "**Observation:** It does not matter how careful we are with our model evaluation techniques, there remains a fundamental uncertainty about the ability of our training data to effectively represent our (possibly infinite) data universe.\n",
        "\n",
        "This uncertainty reflects into our model evaluation. If our training data is a poor representation of the data universe then the models we construct using it will generalize poorly to the rest of the data universe. If our training data is a good representation of the data universe then we can expect that our model will generalize well.\n",
        "\n",
        "Here we will deal with this uncertainty using *confidence intervals*. First, let us define confidence intervals formally. Given a model accuracy, *acc*, then the confidence interval is defined as the probability *p that our model accuracy acc* lies between some lower bound *lb* and some upper bound *ub*,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4xoF2wCQP3j",
        "colab_type": "text"
      },
      "source": [
        "\\begin{equation}\n",
        "Pr(lb ≤ acc ≤ ub) = p\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT8vYd7uQP3l",
        "colab_type": "text"
      },
      "source": [
        "Paraphrasing this equation with *p = 95%*:\n",
        "\n",
        ">We are 95% percent sure that our model accuracy is not worse than *lb* and not better than *ub*.\n",
        "\n",
        "Ultimitely we are interested in the lower and upper bounds of the 95% confidence interval. We can use the following formula to compute the bounds:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKJtmlMqQP3m",
        "colab_type": "text"
      },
      "source": [
        "\\begin{equation}\n",
        "ub = acc + \\sqrt\\frac{acc(1-acc)}{n}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfMrbP_VQP3n",
        "colab_type": "text"
      },
      "source": [
        "\\begin{equation}\n",
        "lb = acc - \\sqrt\\frac{acc(1-acc)}{n}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwGgh8tzQP3p",
        "colab_type": "text"
      },
      "source": [
        "Here, *n* is the number of observations in the testing dataset used to estimate *acc*. The constant 1.96 is called the *z-score* and expresses the fact that we are computing the 95% confidence interval."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prRAw5MPQP3q",
        "colab_type": "text"
      },
      "source": [
        "# Classification Confidence Intervals in Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YDlHnUeQP3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preamble to be able to run notebooks in Jupyter and Colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    import sys\n",
        "    \n",
        "    drive.mount('/content/drive')\n",
        "    notes_home = \"/content/drive/Shared drives/CSC310/notes/\"\n",
        "    user_home = \"/content/drive/My Drive/\"\n",
        "    \n",
        "    sys.path.insert(1,notes_home) # let the notebook access the notes folder\n",
        "\n",
        "except ModuleNotFoundError:\n",
        "    notes_home = \"\" # running native Jupyter environment -- notes home is the same as the notebook\n",
        "    user_home = \"\"  # under Jupyter we assume the user directory is the same as the notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwyWlWVfQP30",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d610da5-4649-4cba-e53c-a8cd0ee1f70b"
      },
      "source": [
        "# cross-validation Iris\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.set_printoptions(formatter={'float_kind':\"{:3.2f}\".format})\n",
        "from sklearn import tree\n",
        "# grab cross validation code\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# get data\n",
        "df = pd.read_csv(notes_home+\"assets/iris.csv\")\n",
        "X  = df.drop(['id','Species'],axis=1)\n",
        "y = df['Species']\n",
        "\n",
        "# set up the model\n",
        "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
        "\n",
        "# do the 5-fold cross validation\n",
        "scores = cross_val_score(model, X, y, cv=5)\n",
        "print(\"Fold Accuracies: {}\".format(scores))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold Accuracies: [0.93 0.97 0.90 0.87 1.00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1BXzdznQP36",
        "colab_type": "text"
      },
      "source": [
        "Let's do a simple example using the function classification_confint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7Xp8xKnQP37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute 95% confidence intervals for classification and regression\n",
        "# problems\n",
        "\n",
        "def classification_confint(acc, n):\n",
        "    '''\n",
        "    Compute the 95% confidence interval for a classification problem.\n",
        "      acc -- classification accuracy\n",
        "      n   -- number of observations used to compute the accuracy\n",
        "    Returns a tuple (lb,ub)\n",
        "    '''\n",
        "    import math\n",
        "    interval = 1.96*math.sqrt(acc*(1-acc)/n)\n",
        "    lb = max(0, acc - interval)\n",
        "    ub = min(1.0, acc + interval)\n",
        "    return (lb,ub)\n",
        "\n",
        "def regression_confint(rs_score, n, k):\n",
        "    '''\n",
        "    Compute the 95% confidence interval for a regression problem.\n",
        "      rs_score -- R^2 score\n",
        "      n        -- number of observations used to compute the R^2 score\n",
        "      k        -- number of independent variables in dataset\n",
        "    Returns a tuple (lb,ub)\n",
        "    Reference:\n",
        "    https://books.google.com/books?id=gkalyqTMXNEC&pg=PA88#v=onepage&q&f=false\n",
        "    '''\n",
        "    import math\n",
        "    interval = 2*math.sqrt((4*rs_score*(1-rs_score)**2*(n-k-1)**2)/((n**2 - 1)*(n+3)))\n",
        "    lb = max(0, rs_score - interval)\n",
        "    ub = min(1.0, rs_score + interval)\n",
        "    return (lb,ub)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYBrfnaWQP3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26f6c90e-5701-4494-ac1c-d4152c366549"
      },
      "source": [
        "observations = 100\n",
        "acc = .88\n",
        "lb,ub = classification_confint(acc,observations)\n",
        "print('Accuracy: {} ({:3.2f},{:3.2f})'.format(acc,lb, ub))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.88 (0.82,0.94)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMIUJ9VsQP4D",
        "colab_type": "text"
      },
      "source": [
        "Now, let's do an actual example using the Wisconsin breast cancer dataset. We want to print out the testing accuracy together with it's 95% confidence interval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhkUEQnMQP4E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba93d149-9551-4bfc-9821-5bb364b5d2f6"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# read the data\n",
        "df = pd.read_csv(notes_home+\"assets/wdbc.csv\")\n",
        "\n",
        "# set up the feature matrix and target vector\n",
        "X  = df.drop(['ID','Diagnosis'],axis=1)\n",
        "y = df['Diagnosis']\n",
        "\n",
        "# split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=2)\n",
        "\n",
        "# set up the tree model object - limit the complexity to put us somewhere in the middle of the graph.\n",
        "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=1)\n",
        "\n",
        "# fit the model on the training set of data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Test results: evaluate the model on the testing set of data\n",
        "y_test_model = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_test_model)\n",
        "observations = X_test.shape[0]\n",
        "lb,up = classification_confint(acc, observations)\n",
        "print(\"Accuracy: {:3.2f} ({:3.2f},{:3.2f})\".format(acc,lb,ub))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.91 (0.86,0.94)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIOYFwPHQP4I",
        "colab_type": "text"
      },
      "source": [
        "## Regression Confidence Intervals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUDhiEBmQP4J",
        "colab_type": "text"
      },
      "source": [
        "When performing regression we use the $R^2$ score to examine the quality of our models. Given that we only use a small training dataset for fitting the model compared to the rest of the data universe it is only natural to ask what the 95% confidence interval for this score might be. We have a formula for that -- it is not as straight forward as the confidence interval for classification,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5GvKTr_QP4K",
        "colab_type": "text"
      },
      "source": [
        "\\begin{equation}\n",
        "lb = R^2 - 2\\sqrt\\frac{4R^2(1-R^2)(n-k-1)}{(n^2-1)(n+3)}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsB6wQ1sQP4L",
        "colab_type": "text"
      },
      "source": [
        "\\begin{equation}\n",
        "ub = R^2 + 2\\sqrt\\frac{4R^2(1-R^2)(n-k-1)}{(n^2-1)(n+3)}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTZC2aOIQP4M",
        "colab_type": "text"
      },
      "source": [
        "Here, n is the number of observations in the validation/testing dataset and k is the number of independent variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63rCPHFRQP4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5cb890f9-aee2-4ba4-ed81-d7f532ab1a2e"
      },
      "source": [
        "# from assets.confint import regression_confint\n",
        "\n",
        "rs_score = .75\n",
        "observations = 100\n",
        "variables = 4 # independent variables\n",
        "\n",
        "lb,ub = regression_confint(rs_score, observations, variables)\n",
        "print(\"R^2 Score: {:3.2f} ({:3.2f}, {:3.2f})\".format(rs_score,lb,ub))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 Score: 0.75 (0.67, 0.83)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoX3TiDNQP4Q",
        "colab_type": "text"
      },
      "source": [
        "Let's look at an actual regression problem and compute the R2 score and it's 95% confidence interval. We will use the cars problem from before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq17TaJ2QP4R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88a3acab-a439-45e0-ba0c-f97810790080"
      },
      "source": [
        "import numpy as np\n",
        "import pandas\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "#from assets.confint import regression_confint\n",
        "\n",
        "# get our dataset\n",
        "cars_df = pandas.read_csv(notes_home+\"assets/cars.csv\")\n",
        "\n",
        "# build model object\n",
        "model = DecisionTreeRegressor(max_depth=None)\n",
        "\n",
        "# fit model\n",
        "# We have to reshape the values array to make 'fit' happy because\n",
        "# the array only has a single feature\n",
        "model.fit(cars_df['speed'].values.reshape(-1,1),cars_df['dist'])\n",
        "\n",
        "# R^2 score\n",
        "rs_score = model.score(cars_df['speed'].values.reshape(-1,1),cars_df['dist'])\n",
        "observations = cars_df.shape[0]\n",
        "variables = 1\n",
        "lb,ub = regression_confint(rs_score, observations, variables)\n",
        "\n",
        "# print out R^2 score with its 95% confidence interval\n",
        "print(\"R^2 Score: {:3.2f} ({:3.2f}, {:3.2f})\".format(rs_score,lb,ub))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 Score: 0.79 (0.69, 0.89)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDtOgPxvQP4V",
        "colab_type": "text"
      },
      "source": [
        "## Statistical Significance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxbnmBugQP4W",
        "colab_type": "text"
      },
      "source": [
        "Besides giving us an idea of the uncertainty of our model the 95% confidence intervals also have something to say about the significance of scores of different models. That is, if the confidence intervals overlap then the difference in model performance of two different models on the same dataset is not statistically significant.\n",
        "\n",
        "Consider the following,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSqQcLuzQP4X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "01265382-311a-4033-a0ad-d0f74b3326d1"
      },
      "source": [
        "#from assets.confint import classification_confint\n",
        "\n",
        "observations = 100\n",
        "\n",
        "# first classifier\n",
        "acc1 = .88\n",
        "lb1,ub1 = classification_confint(acc1,observations)\n",
        "print('Accuracy: {} ({:3.2f},{:3.2f})'.format(acc1,lb1, ub1))\n",
        "\n",
        "# second classifier\n",
        "acc2 = .92\n",
        "lb2,ub2 = classification_confint(acc2,observations)\n",
        "print('Accuracy: {} ({:3.2f},{:3.2f})'.format(acc2,lb2, ub2))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.88 (0.82,0.94)\n",
            "Accuracy: 0.92 (0.87,0.97)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF-T6gF6QP4a",
        "colab_type": "text"
      },
      "source": [
        "Even though the second classifier has a better raw accuracy when we look at the confidence intervals of the two classifiers we see that they overlap. Here we see that the first classifier could potentially have an accuracy of .94 (even better than the raw accuracy of the second classifier). Furthermore, the confidence interval of the second classifier tells us that that classifier could potentially have an accuracy of .87 which is worse than the raw accuracy of the first classifier. For this reason we say that the difference in accuracy of two classifiers is not statistically significant if their confidence intervals overlap."
      ]
    }
  ]
}
