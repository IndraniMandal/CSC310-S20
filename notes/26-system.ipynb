{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"26-system.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPdT0vbME7JH/34M/QqeyUV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Understanding the Underlying Virtual Machine\n","\n","We have already seen that we can issue commands to the underlying system from our notebooks.  The prologue for our notebooks makes use of that functionality in order to import data into the virtual machine (VM).  We can use this functionality to investigate the underlying system further.\n"],"metadata":{"id":"Ov5kcYOrh13q"}},{"cell_type":"markdown","source":["# Processor Architecture and OS\n","\n","First, let's find out a bit more about the hardware and the OS we are running on. Spoiler: we are running on Linux and it has a command called `uname` that lets you probe specifically the hardware and OS versions."],"metadata":{"id":"O60mIEGJiuSx"}},{"cell_type":"code","source":["!echo \"operating system name\"; uname -s \n","!echo \"operating system release\"; uname -r\n","!echo \"operating system version\"; uname -v"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tukDTlPMfPLz","executionInfo":{"status":"ok","timestamp":1638916787918,"user_tz":300,"elapsed":582,"user":{"displayName":"Lutz Hamel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGw3Lpyn8v_49EbZpajVWtDhieE3O3Dn1YoG2yfQ=s64","userId":"10287662568849688016"}},"outputId":"1472e662-294a-43e0-8ce6-05044b85cb37"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["operating system name\n","Linux\n","operating system release\n","5.4.104+\n","operating system version\n","#1 SMP Sat Jun 5 09:50:34 PDT 2021\n"]}]},{"cell_type":"markdown","source":["The `echo` command prints the given string to the terminal.  From the output of the three commands above we learn that we are indeed running on Linux under a particular kernel version.  The deployed version lags about six months behind the currently available kernel version. Finally, we see the OS version.\n","Here, `SMP` means the kernel was built with *symmetric multi-processor support*. #1 indicates the kernel is the result of the first build from the kernel source on the machine where it was built. If it had been tweaked in some way and rebuilt, it would show #2.\n","\n","([Source](https://stackoverflow.com/questions/40916064/how-do-i-know-what-linux-kernel-version-does-a-distribution-use))\n","\n","Next, we'll look at the hardware,"],"metadata":{"id":"wiQdVBPoe2WM"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JIwxp5PkcIV3","executionInfo":{"status":"ok","timestamp":1638916788351,"user_tz":300,"elapsed":438,"user":{"displayName":"Lutz Hamel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGw3Lpyn8v_49EbZpajVWtDhieE3O3Dn1YoG2yfQ=s64","userId":"10287662568849688016"}},"outputId":"f58e5a69-3441-47e1-de04-79c2ed3f959c"},"outputs":[{"output_type":"stream","name":"stdout","text":["machine hardware name\n","x86_64\n","nodename\n","ee19fe26a545\n","processor architecture name\n","x86_64\n"]}],"source":["!echo \"machine hardware name\"; uname -m\n","!echo \"nodename\"; uname -n \n","!echo \"processor architecture name\"; uname -p"]},{"cell_type":"markdown","source":["Here we see that we are running on a 64-bit Intel chip.  The node name is something that only makes sense to Google and has no real impact on our work."],"metadata":{"id":"6sNh0Ip-lD6S"}},{"cell_type":"markdown","source":["# The File System\n","\n","The file system is where the OS stores its and your data.  Therefore, knowing your way around the filesystem a bit might help you identify where your notebook might have saved something or find the file that you want to load into your notebook.\n","\n","Let's start at the beginning.  Where is the default location in the filesystem where our notebook assumes it can find something? We can find this out by issuing the `pwd` (print working directory) command to the underlying Linux system,"],"metadata":{"id":"0k41Zk4mll1i"}},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n2KmOHxomwbC","executionInfo":{"status":"ok","timestamp":1638916788352,"user_tz":300,"elapsed":7,"user":{"displayName":"Lutz Hamel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGw3Lpyn8v_49EbZpajVWtDhieE3O3Dn1YoG2yfQ=s64","userId":"10287662568849688016"}},"outputId":"1e51c4c2-4a0f-4021-8e28-aeb956498c8a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"markdown","source":["OK, our notebook assumes that all data is in a folder called `contents`. Just as aside, the `/` name refers to the *root* folder in Linux which contains all vital OS related information and additional folders.  We can take a peek,"],"metadata":{"id":"qkV9arX7m5qH"}},{"cell_type":"code","source":["!cd ..; ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gOuvf_8In_8V","executionInfo":{"status":"ok","timestamp":1638916788543,"user_tz":300,"elapsed":194,"user":{"displayName":"Lutz Hamel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGw3Lpyn8v_49EbZpajVWtDhieE3O3Dn1YoG2yfQ=s64","userId":"10287662568849688016"}},"outputId":"657d55a6-94ee-4368-c920-73b6d4163b87"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["bin\t datalab  home\t lib64\topt\t    root  srv\t\t     tmp    var\n","boot\t dev\t  lib\t media\tproc\t    run   sys\t\t     tools\n","content  etc\t  lib32  mnt\tpython-apt  sbin  tensorflow-1.15.2  usr\n"]}]},{"cell_type":"markdown","source":["The command `cd ..` (change directory) means go up one level and `ls` means print a listing of the files in that directory. We can see that there are lots of folder with ominous names like `sys`, `boot`, and `root`.  It is best to leave all that alone.  Of course we can also see our `content` folder in that list of folders.\n","\n","We can take a look if there are files already in our `content` folder,"],"metadata":{"id":"6cWrc16DoG-k"}},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZguaEWG3pl4D","executionInfo":{"status":"ok","timestamp":1638916788544,"user_tz":300,"elapsed":5,"user":{"displayName":"Lutz Hamel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGw3Lpyn8v_49EbZpajVWtDhieE3O3Dn1YoG2yfQ=s64","userId":"10287662568849688016"}},"outputId":"19df8d80-bc71-4392-bf82-efee8ef40566"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["sample_data\n"]}]},{"cell_type":"markdown","source":["Sure thing, there is a folder called `sample_data`.  Let's take a peek what's in there,"],"metadata":{"id":"ouQ06yCcpodv"}},{"cell_type":"code","source":["!cd sample_data; ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"apNJ4UvqpzCp","executionInfo":{"status":"ok","timestamp":1638916788743,"user_tz":300,"elapsed":202,"user":{"displayName":"Lutz Hamel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGw3Lpyn8v_49EbZpajVWtDhieE3O3Dn1YoG2yfQ=s64","userId":"10287662568849688016"}},"outputId":"818d991a-ac0d-4062-ff6f-717346db63aa"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["anscombe.json\t\t      mnist_test.csv\n","california_housing_test.csv   mnist_train_small.csv\n","california_housing_train.csv  README.md\n"]}]},{"cell_type":"markdown","source":["We can see a bunch of CSV datafiles which we could play around with.  We also see a `README.md` file.  To find out what that says we can issue the following commands, "],"metadata":{"id":"nxlSEhqGp-eJ"}},{"cell_type":"code","source":["!cd sample_data; cat README.md"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MXnkqAgBqQZ1","executionInfo":{"status":"ok","timestamp":1638916788916,"user_tz":300,"elapsed":174,"user":{"displayName":"Lutz Hamel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGw3Lpyn8v_49EbZpajVWtDhieE3O3Dn1YoG2yfQ=s64","userId":"10287662568849688016"}},"outputId":"d4d9c6db-0289-41ef-fb2c-9f371f6bb3ee"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["This directory includes a few sample datasets to get you started.\n","\n","*   `california_housing_data*.csv` is California housing data from the 1990 US\n","    Census; more information is available at:\n","    https://developers.google.com/machine-learning/crash-course/california-housing-data-description\n","\n","*   `mnist_*.csv` is a small sample of the\n","    [MNIST database](https://en.wikipedia.org/wiki/MNIST_database), which is\n","    described at: http://yann.lecun.com/exdb/mnist/\n","\n","*   `anscombe.json` contains a copy of\n","    [Anscombe's quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet); it\n","    was originally described in\n","\n","    Anscombe, F. J. (1973). 'Graphs in Statistical Analysis'. American\n","    Statistician. 27 (1): 17-21. JSTOR 2682899.\n","\n","    and our copy was prepared by the\n","    [vega_datasets library](https://github.com/altair-viz/vega_datasets/blob/4f67bdaad10f45e3549984e17e1b3088c731503d/vega_datasets/_data/anscombe.json).\n"]}]},{"cell_type":"markdown","source":["Looks like datasets that might be intesting to explore.  However, what we would like to do is to try to understand in a more detailed manner of how we import the data we have been working with for all the previous chapters.  Our prologue looks like this,"],"metadata":{"id":"PBd4fJMhqb1K"}},{"cell_type":"code","source":["###### Set Up #####\n","# verify our folder with the data and module assets is installed\n","# if it is installed make sure it is the latest\n","!test -e ds-assets && cd ds-assets && git pull && cd ..\n","# if it is not installed clone it \n","!test ! -e ds-assets && git clone https://github.com/lutzhamel/ds-assets.git\n","# point to the folder with the assets\n","home = \"ds-assets/assets/\" \n","import sys\n","sys.path.append(home)      # add home folder to module search path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P-iTqnKNre8h","executionInfo":{"status":"ok","timestamp":1638916790127,"user_tz":300,"elapsed":1213,"user":{"displayName":"Lutz Hamel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGw3Lpyn8v_49EbZpajVWtDhieE3O3Dn1YoG2yfQ=s64","userId":"10287662568849688016"}},"outputId":"0267ea7c-d952-4cb5-97b7-6dc78d98fce9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ds-assets'...\n","remote: Enumerating objects: 164, done.\u001b[K\n","remote: Counting objects: 100% (164/164), done.\u001b[K\n","remote: Compressing objects: 100% (143/143), done.\u001b[K\n","remote: Total 164 (delta 60), reused 117 (delta 20), pack-reused 0\u001b[K\n","Receiving objects: 100% (164/164), 7.40 MiB | 29.94 MiB/s, done.\n","Resolving deltas: 100% (60/60), done.\n"]}]},{"cell_type":"markdown","source":["If we now do an `ls` in our contents directory,"],"metadata":{"id":"ogXzVzf-rxwG"}},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8BMxJcS7r3Ow","executionInfo":{"status":"ok","timestamp":1638916790320,"user_tz":300,"elapsed":194,"user":{"displayName":"Lutz Hamel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGw3Lpyn8v_49EbZpajVWtDhieE3O3Dn1YoG2yfQ=s64","userId":"10287662568849688016"}},"outputId":"5ae303c7-cb7e-4ec6-d333-2963b1e61e62"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["ds-assets  sample_data\n"]}]},{"cell_type":"markdown","source":["We can see that the prologue created an additional folder here: `ds-assets`.  This folder contains all the data and Python modules we have been working with in the previous chapters,"],"metadata":{"id":"Pu76GkJAr5P5"}},{"cell_type":"code","source":["!cd ds-assets/assets; ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jLAmkBrKsPye","executionInfo":{"status":"ok","timestamp":1638916790472,"user_tz":300,"elapsed":153,"user":{"displayName":"Lutz Hamel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGw3Lpyn8v_49EbZpajVWtDhieE3O3Dn1YoG2yfQ=s64","userId":"10287662568849688016"}},"outputId":"897adc3b-f0bf-4897-a1ff-40814a2e69f4"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["2fold-xval.png\t\t   mlp_regression2.py\n","5fold-xval.png\t\t   mlp_regression.py\n","abalone.csv\t\t   model-performance-curves.png\n","bootstrap.py\t\t   newsgroups.csv\n","caesarian.csv\t\t   newsgroups-noheaders.csv\n","cars.csv\t\t   PandasPythonForDataScience.jpg\n","classification1.jpg\t   PandasPythonForDataScience.pdf\n","classification2.jpg\t   pdf-badge.png\n","classification3.jpg\t   perceptron-eq.jpg\n","colab-badge.afdesign\t   perceptron.jpg\n","colab-icon.afdesign\t   perceptron.r\n","colab-icon.png\t\t   perceptron-search.png\n","confint.py\t\t   perceptron-train.jpg\n","confusion1.png\t\t   pipeline.png\n","confusion2.png\t\t   regression1.jpg\n","crohnd.csv\t\t   rs.png\n","cross-validated-curve.png  shuttle.csv\n","data-science.jpg\t   shuttle.pdf\n","divorce.csv\t\t   sobar-72.csv\n","divorce-readme.txt\t   swans.jpg\n","elbow.py\t\t   tennis.csv\n","github-icon.png\t\t   tennis_numeric.csv\n","google_drive.py\t\t   training-curves.jpg\n","grid-stability.csv\t   train-test-curves.png\n","helloagain.py\t\t   train-test-data.png\n","helloworld.py\t\t   tree-model.png\n","iris.csv\t\t   tree_regression2.py\n","kmeans-steps.png\t   tree_regression.py\n","kmeans-steps.pptx\t   tree_regr_grid.py\n","knn.png\t\t\t   tree-viz.png\n","knn_regression2.py\t   treeviz.py\n","knn_regression.py\t   wdbc.csv\n","knn_regr_grid.py\t   yellowstone.jpg\n","mammals.csv\t\t   youtube-icon.png\n","mlp.py\n"]}]},{"cell_type":"markdown","source":["By the way, you can explore all this in a visual manner by clicking on the folder icon in the left, vertical navigation bar."],"metadata":{"id":"l3K67GuBsiFV"}},{"cell_type":"markdown","source":["# Mounting your Google Drive\n","\n","In the first chapters we talked about accessing files on Google Drive via 'share links'.  There is another way of getting files on your Google Drive into the Colab VM: We can mount Google Drive into the VM filesystem.\n","\n","Here is the code that will accomplish this,"],"metadata":{"id":"12R57B-Qs9c4"}},{"cell_type":"code","source":["mount_point = '/content/drive'\n","from google.colab import drive\n","drive.mount(mount_point)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sTZJRyDwCmbZ","executionInfo":{"status":"ok","timestamp":1638916850579,"user_tz":300,"elapsed":8075,"user":{"displayName":"Lutz Hamel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGw3Lpyn8v_49EbZpajVWtDhieE3O3Dn1YoG2yfQ=s64","userId":"10287662568849688016"}},"outputId":"2db4271b-2cfd-48de-e653-bc83677c380a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["For the mount point we have to pick a directory that has no files in it.  In this case the 'drive' folder fits the bill.\n","Once we have mounted the Google Drive we can look at its contents,"],"metadata":{"id":"Qy7qkfrcDqKw"}},{"cell_type":"code","source":["!ls /content/drive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g8riBm5BHkWU","executionInfo":{"status":"ok","timestamp":1638917897578,"user_tz":300,"elapsed":476,"user":{"displayName":"Lutz Hamel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGw3Lpyn8v_49EbZpajVWtDhieE3O3Dn1YoG2yfQ=s64","userId":"10287662568849688016"}},"outputId":"bb6830c8-f05e-4f32-c81f-e5040dca4bc4"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["MyDrive  Shareddrives\n"]}]},{"cell_type":"markdown","source":["We can see that two directories have been created in our mount point.  I have a directory called `Example-Directory` in `MyDrive` which in turn contains the `iris-local.csv` file,"],"metadata":{"id":"ncuiAkYcHtvt"}},{"cell_type":"code","source":["!ls /content/drive/MyDrive/Example-Directory/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o_r5LgndIWVZ","executionInfo":{"status":"ok","timestamp":1638918184367,"user_tz":300,"elapsed":166,"user":{"displayName":"Lutz Hamel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGw3Lpyn8v_49EbZpajVWtDhieE3O3Dn1YoG2yfQ=s64","userId":"10287662568849688016"}},"outputId":"93d2e79b-986f-43e4-e6ae-0f90446900f8"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["iris-local.csv\n"]}]},{"cell_type":"markdown","source":["That means we can this file from that directory into a Pandas dataframe,"],"metadata":{"id":"C_upfjyxIzFn"}},{"cell_type":"code","source":["import pandas as pd\n","path = '/content/drive/MyDrive/Example-Directory/'\n","df = pd.read_csv(path+'iris-local.csv')\n","df.head(n=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"GgqXv4DPI7Aj","executionInfo":{"status":"ok","timestamp":1638918379601,"user_tz":300,"elapsed":137,"user":{"displayName":"Lutz Hamel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGw3Lpyn8v_49EbZpajVWtDhieE3O3Dn1YoG2yfQ=s64","userId":"10287662568849688016"}},"outputId":"e9b54d09-de5c-4652-ed94-cca8bca38be9"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>Sepal.Length</th>\n","      <th>Sepal.Width</th>\n","      <th>Petal.Length</th>\n","      <th>Petal.Width</th>\n","      <th>Species</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>5.4</td>\n","      <td>3.9</td>\n","      <td>1.7</td>\n","      <td>0.4</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>4.6</td>\n","      <td>3.4</td>\n","      <td>1.4</td>\n","      <td>0.3</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>5.0</td>\n","      <td>3.4</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>4.4</td>\n","      <td>2.9</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>4.9</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.1</td>\n","      <td>setosa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n","0   1           5.1          3.5           1.4          0.2  setosa\n","1   2           4.9          3.0           1.4          0.2  setosa\n","2   3           4.7          3.2           1.3          0.2  setosa\n","3   4           4.6          3.1           1.5          0.2  setosa\n","4   5           5.0          3.6           1.4          0.2  setosa\n","5   6           5.4          3.9           1.7          0.4  setosa\n","6   7           4.6          3.4           1.4          0.3  setosa\n","7   8           5.0          3.4           1.5          0.2  setosa\n","8   9           4.4          2.9           1.4          0.2  setosa\n","9  10           4.9          3.1           1.5          0.1  setosa"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["The file is as expected in that it describes the iris flowers.  Of course we could create a dataframe and write it to the drive using the `to_csv` member function of dataframes as well."],"metadata":{"id":"CsEs6-_xJtuw"}}]}