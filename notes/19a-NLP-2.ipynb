{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"NcBu5VHyfb_U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682167850102,"user_tz":240,"elapsed":1297,"user":{"displayName":"Lutz Hamel","userId":"10287662568849688016"}},"outputId":"ace29c5a-65d2-4b2d-ce7c-937da39a22ae"},"source":["###### Set Up #####\n","# verify our folder with the data and module assets is installed\n","# if it is installed make sure it is the latest\n","!test -e ds-assets && cd ds-assets && git pull && cd ..\n","# if it is not installed clone it \n","!test ! -e ds-assets && git clone https://github.com/lutzhamel/ds-assets.git\n","# point to the folder with the assets\n","home = \"ds-assets/assets/\" \n","import sys\n","sys.path.append(home)      # add home folder to module search path"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ds-assets'...\n","remote: Enumerating objects: 180, done.\u001b[K\n","remote: Counting objects: 100% (16/16), done.\u001b[K\n","remote: Compressing objects: 100% (10/10), done.\u001b[K\n","remote: Total 180 (delta 6), reused 16 (delta 6), pack-reused 164\u001b[K\n","Receiving objects: 100% (180/180), 7.49 MiB | 22.11 MiB/s, done.\n","Resolving deltas: 100% (66/66), done.\n"]}]},{"cell_type":"markdown","metadata":{"id":"V5Aqfl2Lfb_X"},"source":["# NLP & ML: Classification\n","\n","We saw that we convert text document into a ‘vector model’ (bag-of-words).\n","\n","The vector model allows us to perform mathematical analysis on documents - “which documents are similar to each other?”\n","\n","> Next question: can we construct machine learning models on document collections using the vector model?\n","\n","**Yes!** \n","\n","We start with classifiers!\n"]},{"cell_type":"markdown","metadata":{"id":"goe8Cr5Rfb_X"},"source":["Consider again our news article data set.\n","\n","We would like to construct a classifier that can correctly classifier political and science documents.\n","\n","We will begin with our Decision Tree model.\n","\n","And then apply  our KNN algorithm (k nearest neighbors). Since documents are considered point in an n-dimensional space KNN seems well suited for this problem."]},{"cell_type":"markdown","metadata":{"id":"ZVDJGfo9fb_Y"},"source":["## Data"]},{"cell_type":"code","metadata":{"id":"z2Ph5Nlcfb_Y","executionInfo":{"status":"ok","timestamp":1682167855250,"user_tz":240,"elapsed":5150,"user":{"displayName":"Lutz Hamel","userId":"10287662568849688016"}}},"source":["# setup\n","import pandas as pd\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","from confint import classification_confint\n","from sklearn.feature_extraction.text import CountVectorizer\n","from nltk.stem import PorterStemmer\n","from treeviz import tree_print"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Lx4nJN-fb_Z","colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"status":"ok","timestamp":1682167855608,"user_tz":240,"elapsed":362,"user":{"displayName":"Lutz Hamel","userId":"10287662568849688016"}},"outputId":"5b144008-c721-4b1a-f955-78adc231e638"},"source":["print(\"******** data **********\")\n","\n","# get the newsgroup database\n","newsgroups = pd.read_csv(home+\"newsgroups-noheaders.csv\")\n","#newsgroups = pd.read_csv(home+\"newsgroups.csv\")\n","newsgroups.head(n=10)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["******** data **********\n"]},{"output_type":"execute_result","data":{"text/plain":["                                                text     label\n","0  \\nIn billions of dollars (%GNP):\\nyear  GNP   ...     space\n","1   ajteel@dendrite.cs.Colorado.EDU (A.J. Teel) w...     space\n","2  \\nMy opinion is this:  In a society whose econ...     space\n","3  Ahhh, remember the days of Yesterday?  When we...     space\n","4  \\n\"...a la Chrysler\"??  Okay kids, to the near...     space\n","5  \\n   As for advertising -- sure, why not?  A N...  politics\n","6  \\n  What, pray tell, does this mean? Just who ...     space\n","7  \\nWhere does the shadow come from?  There's no...  politics\n","8                                       ^^^^^^^^^...  politics\n","9  #Yet, when a law was proposed for Virginia tha...     space"],"text/html":["\n","  <div id=\"df-0e09f756-fba6-4909-9974-d89e1c0ee7dd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>\\nIn billions of dollars (%GNP):\\nyear  GNP   ...</td>\n","      <td>space</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ajteel@dendrite.cs.Colorado.EDU (A.J. Teel) w...</td>\n","      <td>space</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>\\nMy opinion is this:  In a society whose econ...</td>\n","      <td>space</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Ahhh, remember the days of Yesterday?  When we...</td>\n","      <td>space</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>\\n\"...a la Chrysler\"??  Okay kids, to the near...</td>\n","      <td>space</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>\\n   As for advertising -- sure, why not?  A N...</td>\n","      <td>politics</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>\\n  What, pray tell, does this mean? Just who ...</td>\n","      <td>space</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>\\nWhere does the shadow come from?  There's no...</td>\n","      <td>politics</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>^^^^^^^^^...</td>\n","      <td>politics</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>#Yet, when a law was proposed for Virginia tha...</td>\n","      <td>space</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e09f756-fba6-4909-9974-d89e1c0ee7dd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0e09f756-fba6-4909-9974-d89e1c0ee7dd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0e09f756-fba6-4909-9974-d89e1c0ee7dd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"6dTMmTB8fb_b","colab":{"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"status":"ok","timestamp":1682167895772,"user_tz":240,"elapsed":10378,"user":{"displayName":"Lutz Hamel","userId":"10287662568849688016"}},"outputId":"4c8a4dac-dd73-4cdf-a253-1b31902fff4e"},"source":["print(\"******** docarray **********\")\n","\n","# build the stemmer object\n","stemmer = PorterStemmer()\n","\n","# build a new default analyzer using CountVectorizer that only uses words: [a-zA-Z]+\n","# also eliminate stop words\n","analyzer= CountVectorizer(analyzer = \"word\", \n","                          stop_words = 'english',\n","                          token_pattern = \"[a-zA-Z]+\").build_analyzer()\n","\n","# build a new analyzer that stems using the default analyzer to create the words to be stemmed\n","def stemmed_words(doc):\n","    return [stemmer.stem(w) for w in analyzer(doc)]\n","\n","# build docarray\n","vectorizer = CountVectorizer(analyzer=stemmed_words,\n","                             #analyzer=analyzer,\n","                             binary=True,\n","                             min_df=2) # each word has to appear at least twice\n","docarray = vectorizer.fit_transform(newsgroups['text']).toarray()\n","docarray.shape\n","doc_df = pd.DataFrame(docarray, columns=list(vectorizer.get_feature_names_out()))\n","doc_df.head()"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["******** docarray **********\n"]},{"output_type":"execute_result","data":{"text/plain":["   aa  abandon  abbey  abc  abil  abl  aboard  abolish  abort  abroad  ...  \\\n","0   0        0      0    0     0    0       0        0      0       0  ...   \n","1   0        0      0    0     0    0       0        0      0       0  ...   \n","2   0        0      0    0     0    0       0        0      0       0  ...   \n","3   0        0      0    0     0    0       0        0      0       0  ...   \n","4   0        0      0    0     0    0       0        0      0       0  ...   \n","\n","   yugoslavia  yup  z  zealand  zenit  zero  zeta  zip  zone  zoo  \n","0           0    0  0        0      0     0     0    0     0    0  \n","1           0    0  0        0      0     0     0    0     0    0  \n","2           0    0  0        0      0     0     0    0     0    0  \n","3           0    0  0        0      0     0     0    0     0    0  \n","4           0    0  0        0      0     1     0    0     0    0  \n","\n","[5 rows x 6045 columns]"],"text/html":["\n","  <div id=\"df-acc26fe4-6924-46e9-a862-11bdc9a4f2cc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>aa</th>\n","      <th>abandon</th>\n","      <th>abbey</th>\n","      <th>abc</th>\n","      <th>abil</th>\n","      <th>abl</th>\n","      <th>aboard</th>\n","      <th>abolish</th>\n","      <th>abort</th>\n","      <th>abroad</th>\n","      <th>...</th>\n","      <th>yugoslavia</th>\n","      <th>yup</th>\n","      <th>z</th>\n","      <th>zealand</th>\n","      <th>zenit</th>\n","      <th>zero</th>\n","      <th>zeta</th>\n","      <th>zip</th>\n","      <th>zone</th>\n","      <th>zoo</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 6045 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acc26fe4-6924-46e9-a862-11bdc9a4f2cc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-acc26fe4-6924-46e9-a862-11bdc9a4f2cc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-acc26fe4-6924-46e9-a862-11bdc9a4f2cc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"qut5LJe8drZ1"},"source":["## Decision Tree"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p3vQAlJEYsAm","executionInfo":{"status":"ok","timestamp":1682167923014,"user_tz":240,"elapsed":27248,"user":{"displayName":"Lutz Hamel","userId":"10287662568849688016"}},"outputId":"bb23b2d0-bf07-404e-f624-3e5f5ebd886f"},"source":["print(\"******** model **********\")\n","\n","\n","# Decision Tree\n","model = DecisionTreeClassifier(random_state=0)\n","\n","# grid search\n","param_grid = {'max_depth': list(range(1,31))}\n","grid = GridSearchCV(model, param_grid, cv=3, verbose=10, n_jobs=-1)\n","grid.fit(docarray, newsgroups['label'])\n","print(\"Grid Search: best parameters: {}\".format(grid.best_params_))\n","tree_print(grid.best_estimator_,doc_df)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["******** model **********\n","Fitting 3 folds for each of 30 candidates, totalling 90 fits\n","Grid Search: best parameters: {'max_depth': 28}\n","if space =< 0.5: \n","  |then if orbit =< 0.5: \n","  |  |then if peopl =< 0.5: \n","  |  |  |then if clinton =< 0.5: \n","  |  |  |  |then if homosexu =< 0.5: \n","  |  |  |  |  |then if tax =< 0.5: \n","  |  |  |  |  |  |then if parti =< 0.5: \n","  |  |  |  |  |  |  |then if crime =< 0.5: \n","  |  |  |  |  |  |  |  |then if trial =< 0.5: \n","  |  |  |  |  |  |  |  |  |then if libertarian =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |then if statement =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |then if liber =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |then if argument =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |then if u =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if drug =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if presid =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if yeah =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if hous =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if gay =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if like =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if nation =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if frank =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if rahul =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if riot =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if bail =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if drieux =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if europ =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if just =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then politics\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else if power =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else if evid =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then politics\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else if crap =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if polic =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if germani =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if percentag =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if studi =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then politics\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else if russian =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else if beer =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |else if lehrer =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if wouldn =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if florida =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |  |  |  |  |  |  |  |  |else if certainli =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |then space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |  |  |  |  |else if guess =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |then space\n","  |  |  |  |  |  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |else if imagin =< 0.5: \n","  |  |  |  |  |  |  |then space\n","  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |else space\n","  |  |  |  |else if legisl =< 0.5: \n","  |  |  |  |  |then space\n","  |  |  |  |  |else politics\n","  |  |  |else if nasa =< 0.5: \n","  |  |  |  |then if rocket =< 0.5: \n","  |  |  |  |  |then if sky =< 0.5: \n","  |  |  |  |  |  |then if moon =< 0.5: \n","  |  |  |  |  |  |  |then if optimist =< 0.5: \n","  |  |  |  |  |  |  |  |then if miner =< 0.5: \n","  |  |  |  |  |  |  |  |  |then if planetari =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |then if floor =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |then if dusk =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |then if shuttl =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |then if phi =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if qb =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if fred =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if aloud =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then if mail =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else if regard =< 0.5: \n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |then politics\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else space\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |  |  |  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |  |  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |  |  |else politics\n","  |  |  |  |  |  |else politics\n","  |  |  |  |  |else politics\n","  |  |  |  |else if thank =< 0.5: \n","  |  |  |  |  |then politics\n","  |  |  |  |  |else space\n","  |  |else politics\n","  |else if democrat =< 0.5: \n","  |  |then if radioact =< 0.5: \n","  |  |  |then if gay =< 0.5: \n","  |  |  |  |then if ukrain =< 0.5: \n","  |  |  |  |  |then politics\n","  |  |  |  |  |else space\n","  |  |  |  |else space\n","  |  |  |else space\n","  |  |else if structur =< 0.5: \n","  |  |  |then space\n","  |  |  |else politics\n","<---------------------------------------------------------------------------------->\n","Tree Depth:  28\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8E8XLIGjZIH5","executionInfo":{"status":"ok","timestamp":1682167923185,"user_tz":240,"elapsed":181,"user":{"displayName":"Lutz Hamel","userId":"10287662568849688016"}},"outputId":"949a436a-afcc-44a3-c091-532316ffc006"},"source":["print(\"******** Accuracy **********\")\n","\n","# accuracy of best model with confidence interval\n","best_model = grid.best_estimator_\n","predict_y = best_model.predict(docarray)\n","acc = accuracy_score(newsgroups['label'], predict_y)\n","lb,ub = classification_confint(acc,docarray.shape[0])\n","print(\"Accuracy: {:3.2f} ({:3.2f},{:3.2f})\".format(acc,lb,ub))"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["******** Accuracy **********\n","Accuracy: 0.94 (0.92,0.95)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZfWC5Ilocqr2","executionInfo":{"status":"ok","timestamp":1682167923186,"user_tz":240,"elapsed":5,"user":{"displayName":"Lutz Hamel","userId":"10287662568849688016"}},"outputId":"5d834860-2bcb-483c-ad7f-3ceaf702bbf6"},"source":["print(\"******** confusion matrix **********\")\n","\n","# build the confusion matrix\n","cats = ['politics','space']\n","cm = confusion_matrix(newsgroups['label'], predict_y, labels=cats)\n","cm_df = pd.DataFrame(cm, index=cats, columns=cats)\n","print(\"Confusion Matrix:\\n{}\".format(cm_df))"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["******** confusion matrix **********\n","Confusion Matrix:\n","          politics  space\n","politics       580      0\n","space           67    391\n"]}]},{"cell_type":"markdown","metadata":{"id":"N0BitS8NcsNW"},"source":["## KNN"]},{"cell_type":"code","metadata":{"id":"ZIAw501Qfb_c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682167928786,"user_tz":240,"elapsed":5603,"user":{"displayName":"Lutz Hamel","userId":"10287662568849688016"}},"outputId":"86b22c02-5d52-4afc-b6e1-32ff181edb7a"},"source":["print(\"******** model **********\")\n","\n","\n","# KNN\n","model = KNeighborsClassifier()\n","\n","# grid search\n","param_grid = {'n_neighbors': list(range(1,11))}\n","grid = GridSearchCV(model, param_grid, cv=3, verbose=10, n_jobs=-1)\n","grid.fit(docarray, newsgroups['label'])\n","print(\"Grid Search: best parameters: {}\".format(grid.best_params_))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["******** model **********\n","Fitting 3 folds for each of 10 candidates, totalling 30 fits\n","Grid Search: best parameters: {'n_neighbors': 4}\n"]}]},{"cell_type":"code","metadata":{"id":"rXytX14mfb_c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682167929427,"user_tz":240,"elapsed":651,"user":{"displayName":"Lutz Hamel","userId":"10287662568849688016"}},"outputId":"aaa341f2-292f-40f4-d172-6674b3de5401"},"source":["print(\"******** Accuracy **********\")\n","\n","# accuracy of best model with confidence interval\n","best_model = grid.best_estimator_\n","predict_y = best_model.predict(docarray)\n","acc = accuracy_score(newsgroups['label'], predict_y)\n","lb,ub = classification_confint(acc,docarray.shape[0])\n","print(\"Accuracy: {:3.2f} ({:3.2f},{:3.2f})\".format(acc,lb,ub))"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["******** Accuracy **********\n","Accuracy: 0.79 (0.76,0.81)\n"]}]},{"cell_type":"code","metadata":{"id":"vrNMB9tyfb_d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682167929428,"user_tz":240,"elapsed":4,"user":{"displayName":"Lutz Hamel","userId":"10287662568849688016"}},"outputId":"eabe0930-9e15-4159-954d-f6a5a65de33f"},"source":["print(\"******** confusion matrix **********\")\n","\n","# build the confusion matrix\n","cats = ['politics','space']\n","cm = confusion_matrix(newsgroups['label'], predict_y, labels=cats)\n","cm_df = pd.DataFrame(cm, index=cats, columns=cats)\n","print(\"Confusion Matrix:\\n{}\".format(cm_df))"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["******** confusion matrix **********\n","Confusion Matrix:\n","          politics  space\n","politics       408    172\n","space           49    409\n"]}]},{"cell_type":"markdown","metadata":{"id":"1H94tYstfb_d"},"source":["## Naive Bayes (NB)\n","\n","* “Standard” model for text processing\n","* Fast to train, has no problems with very high dimensional data\n","* NB is a classification technique based on Bayes’ Theorem with an assumption of independence among predictors. \n","* In simple terms, a NB classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature. \n","* For example, a fruit may be considered to be an apple if it is red, round, and about 3 inches in diameter. Even if these features depend on each other or upon the existence of the other features, all of these properties independently contribute to the probability that this fruit is an apple and that is why it is known as ‘Naive’.\n"]},{"cell_type":"markdown","metadata":{"id":"Gb_q1xG5fb_e"},"source":["### The Mathematics\n","\n","[Source](https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained)\n","\n","Bayes theorem provides a way of calculating posterior probability $P(c|x)$ from $P(c)$, $P(x)$ and $P(x|c)$ with the equation, \n","\n","<center>\n","$\n","P(c|x) = \\frac{P(x|c)P(c)}{P(x)}\n","$\n","</center>\n","\n","where\n","  * $P(c|x)$ is the posterior probability of class (c, target) given predictor (x, attributes).\n","  * $P(c)$ is the prior probability of class.\n","  * $P(x|c)$ is the likelihood which is the probability of predictor given class.\n","  * $P(x)$ is the prior probability of predictor.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"N-eW3am6fb_e"},"source":["### Example\n","\n","Let's assume we have a predictor `Weather` and a target `Play` that contains classes (left table below).  \n","\n","<img src=\"https://www.analyticsvidhya.com/wp-content/uploads/2015/08/Bayes_41.png\">\n","\n","We want to compute if we play tennis when sunny.  That is we compute the two probabilities,\n","\n","1. $P(Yes|Sunny)$\n","1. $P(No|Sunny)$\n","\n","and then pick the statement with the higher probability."]},{"cell_type":"markdown","metadata":{"id":"qg4Y_kGDfb_f"},"source":["Basically, NB just counts, let's look at $P(Yes|Sunny)$,\n","\n","$P(Yes|Sunny) = \\frac{P(Sunny|Yes)P(Yes)}{P(Sunny)} = \\frac{3/9\\times 9/14}{5/14} = \\frac{.33 \\times .64}{.36}=.60$\n","\n","Now, let's look at $P(No|Sunny)$,\n","\n","$P(No|Sunny) = \\frac{P(Sunny|No)P(No)}{P(Sunny)} = \\frac{2/5\\times 5/14}{5/14} = \\frac{.40 \\times .36}{.36}=.40$\n","\n","We are playing tennis when sunny because the posterior probability $P(Yes|Sunny)$ is higher."]},{"cell_type":"markdown","source":["In order to predict a class based on multiple attributes we use the following formula,\n","\n","$P(c|X) = P(c|x_1)\\times P(c|x_2)\\times\\ldots \\times P(c|x_n)\\times P(c)$\n","\n","where\n","\n","$X = (x_1,x_2,\\ldots,x_n)$"],"metadata":{"id":"vxRk5tWPX44p"}},{"cell_type":"markdown","source":["### Text Classification"],"metadata":{"id":"17ixDJkoIMmX"}},{"cell_type":"markdown","metadata":{"id":"kB8TjXIkfb_f"},"source":["Let’s take our text classification problem and use a Naive Bayes classifier on it.\n","\n","The setup and data prep is the same as in the case of the KNN classifier."]},{"cell_type":"code","metadata":{"id":"MFeBwTMPfb_f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682167929933,"user_tz":240,"elapsed":508,"user":{"displayName":"Lutz Hamel","userId":"10287662568849688016"}},"outputId":"5ee0acae-22b5-4068-8ba8-f96296eda6e8"},"source":["\n","from sklearn.naive_bayes import MultinomialNB \n","## Naive Bayes\n","\n","print(\"******** model **********\")\n","\n","\n","# Naive Bayes\n","model = MultinomialNB()\n","# NOTE: NB does not have any hyper-parameters - no overfitting - no searching over parameter space!\n","model.fit(docarray, newsgroups['label'])\n","\n","\n","print(\"******** Accuracy **********\")\n","\n","# accuracy of best model with confidence interval\n","best_model = model\n","predict_y = best_model.predict(docarray)\n","acc = accuracy_score(newsgroups['label'], predict_y)\n","lb,ub = classification_confint(acc,docarray.shape[0])\n","print(\"Accuracy: {:3.2f} ({:3.2f},{:3.2f})\".format(acc,lb,ub))\n","\n","print(\"******** confusion matrix **********\")\n","\n","# build the confusion matrix\n","cats = ['politics','space']\n","cm = confusion_matrix(newsgroups['label'], predict_y, labels=cats)\n","cm_df = pd.DataFrame(cm, index=cats, columns=cats)\n","print(\"Confusion Matrix:\\n{}\".format(cm_df))"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["******** model **********\n","******** Accuracy **********\n","Accuracy: 0.96 (0.95,0.98)\n","******** confusion matrix **********\n","Confusion Matrix:\n","          politics  space\n","politics       556     24\n","space           13    445\n"]}]},{"cell_type":"markdown","metadata":{"id":"2w-o8bV1fb_g"},"source":["Trains very fast and has a higher accuracy than DT or KNN and the difference in accuracy is statistically significant!\n","\n","> NB does not have any hyper-parameters - no overfitting - no searching over parameter space!\n"]},{"cell_type":"markdown","metadata":{"id":"XP4MuOaafb_h"},"source":["#Assignment \n","\n","## Problem Set\n","\n","For this exercise you will build a classifier that can distinguish real news from fake news. A training set for this is available here: https://raw.githubusercontent.com/lutzhamel/fake-news/master/data/fake_or_real_news.csv.\n","\n","A good starting point for your project is the [template-fake-news.ipynb](https://colab.research.google.com/drive/1mi_bwUrsIjkivVfyASxlhYEBaizPmueE#scrollTo=m-8riFxGJhIM) file.\n","\n","The fields you are interested in are ‘text’ and ‘label’ with the obvious interpretations.\n","\n","## Here are the action items for this exercise:\n","\n","* Use the binary vector model and text preprocessing techniques  to construct a training data set as a docterm dataframe as discussed in class. At minimum you have to apply the following preprocessing steps:\n","   * Word only analysis - reject anything and everything that is not a word where a word is defined as only consisting of upper and lower case letters.\n","   * Include stop words.\n","   * Include stemming.\n","   * Set the minimum doc frequency to 2.\n","\n","* Determine the dimensions of your final vector model and print out the first 10 dimensions\n","\n","* Use the docterm dataframe computed in (1) to construct a Naive Bayes classifier.\n","\n","* Compute the accuracy, 95% confidence interval, and the confusion matrix for the classifier.  Comment on the kind of errors that your model makes given the confusion matrix.\n","\n","**Extra Credit**: Try the same thing but instead of ‘text’ use ‘title’ for your training text. How does a classifier built on this data set compare to the original classifier?\n","\n","## Deliverables\n","\n","Submit your notebook links in BrightSpace.  Don't forget to set the permissions appropriately so that anybody at URI can view the notebook.\n","\n","For more details see BrightSpace."]},{"cell_type":"code","metadata":{"id":"Zr8jF1n_fb_h","executionInfo":{"status":"ok","timestamp":1682167929934,"user_tz":240,"elapsed":6,"user":{"displayName":"Lutz Hamel","userId":"10287662568849688016"}}},"source":[],"execution_count":12,"outputs":[]}]}